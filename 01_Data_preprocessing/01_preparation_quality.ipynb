{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation quality from Khandelwal methodology\n",
    "\n",
    "This notebook has been generated on 08/14/2020\n",
    "\n",
    "## Objective(s)\n",
    "\n",
    "*  Compute Kandhelwal quality for the table created in the US 1, US 1 Prepare baseline dataset. The quality is computed at the firm product-destination-level for each year in our sample. \n",
    "\n",
    "* Add the following Fixed effect variables:\n",
    "  * Name\n",
    "  * firm-product-eligibility\n",
    "  * HS4-year-eligibility\n",
    "  * city-year \n",
    "  * destination-year\n",
    "  * Product-year\n",
    "\n",
    "## Metadata\n",
    "\n",
    "* Task type:\n",
    "  * Jupyter Notebook\n",
    "* Users: :\n",
    "  * Thomas Pernet\n",
    "* Watchers:\n",
    "  * Thomas Pernet\n",
    "* Estimated Log points:\n",
    "  * One being a simple task, 15 a very difficult one\n",
    "  *  5\n",
    "* Task tag\n",
    "  *  #computation,#linear-regression,#quality\n",
    "* Toggl Tag\n",
    "  * #variable-computation\n",
    "\n",
    "## Input Cloud Storage [AWS/GCP]\n",
    "\n",
    "* BigQuery \n",
    "  * Table: VAT_export_2003_2010 \n",
    "    * Notebook construction file (data lineage) \n",
    "      * md : [00_preparation_baseline_db.md](https://github.com/thomaspernet/VAT_rebate_quality_china/blob/master/01_Data_preprocessing/00_preparation_baseline_db.md)\n",
    "      \n",
    "* Spreadsheet\n",
    "  * Name: [Sigmas_3digit_China](https://docs.google.com/spreadsheets/d/1YLr4n2xLWKIxYftf8ODSMw6tsoiukLMxs1L5mopTDfk/edit?usp=sharing)\n",
    "  * Sheet:Sigmas \n",
    "  * ID:1YLr4n2xLWKIxYftf8ODSMw6tsoiukLMxs1L5mopTDfk \n",
    "  * Notebook construction file (data lineage) \n",
    "    * From [sigma - Google Drive](https://drive.google.com/drive/folders/1KLkMm-p3_rjrHDbQcaIRlRmQwsGymoSB?usp=sharing)\n",
    "\n",
    "## Destination Output/Delivery\n",
    "\n",
    "* BigQuery: \n",
    "  * Project: valid-pagoda-132423 \n",
    "  * Database:China \n",
    "  *  Table: quality_vat_export_2003_2010    \n",
    "\n",
    "## Things to know (Steps, Attention points or new flow of information)\n",
    "\n",
    "* Dynalist:\n",
    "  * A cheat sheet about quality computed is available [here](https://dynalist.io/d/hnOnutKtJdI6IPjlF_IrsBQi#z=WDnMEWuP5UGr49qFyXifoEtX)\n",
    "* Previous Stata [code](https://drive.google.com/file/d/1MYf5L_5D99BY9bq0fpo4_7K3jfMGllvq/view?usp=sharing)\n",
    "* paper:\n",
    "  * The genuine paper to compute the quality can be found [here](https://paperpile.com/shared/T5Njl6) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "## inputs\n",
    "\n",
    "- Filename: Sigmas_3digit_China\n",
    "- Link: https://docs.google.com/spreadsheets/d/1YLr4n2xLWKIxYftf8ODSMw6tsoiukLMxs1L5mopTDfk/edit?usp=sharing\n",
    "- Type: Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os, re,  requests, json \n",
    "from GoogleDrivePy.google_authorization import authorization_service\n",
    "from GoogleDrivePy.google_platform import connect_cloud_platform\n",
    "from GoogleDrivePy.google_drive import connect_drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent)\n",
    "project = 'valid-pagoda-132423'\n",
    "\n",
    "\n",
    "auth = authorization_service.get_authorization(\n",
    "    path_credential_gcp = \"{}/creds/service.json\".format(parent_path),\n",
    "    path_credential_drive = \"{}/creds\".format(parent_path),\n",
    "    verbose = False#\n",
    ")\n",
    "\n",
    "gcp_auth = auth.authorization_gcp()\n",
    "gd_auth = auth.authorization_drive()\n",
    "gcp = connect_cloud_platform.connect_console(project = project, \n",
    "                                             service_account = gcp_auth) \n",
    "drive = connect_drive.drive_operations(gd_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = drive.upload_data_from_spreadsheet(\n",
    "    sheetID = '1YLr4n2xLWKIxYftf8ODSMw6tsoiukLMxs1L5mopTDfk',\n",
    "    sheetName = 'Sigmas',\n",
    "\t to_dataframe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filename: VAT_export_2003_2010\n",
    "- Link: https://console.cloud.google.com/bigquery?project=valid-pagoda-132423&p=valid-pagoda-132423&d=China&t=VAT_export_2003_2010&page=table\n",
    "- Type: Table\n",
    "\n",
    "Save locally because too slow to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "          \"SELECT * \"\n",
    "            \"FROM China.VAT_export_2003_2010 \"\n",
    "\n",
    "        )\n",
    "df_vat = gcp.upload_data_from_bigquery(query = query, location = 'US')\n",
    "df_vat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_vat.to_csv('../00_Data_catalogue/temporary_local_data/VAT_export_2003_2010.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "1. Merge Sigma\n",
    "2. Create additional variables:\n",
    "    - sigma_price = sigma * log(unit price)\n",
    "    - y = log quantity + sigma_price\n",
    "    - FE_ct = country year fixed effect\n",
    "3. Compute the residual\n",
    "4. Compute quality:\n",
    "    - Adjusted: log(unit price) - residual\n",
    "    - Kandhelwal : residual /(sigma - 1)\n",
    "5. Add Fixed effect\n",
    "    * Name\n",
    "    * firm-product-eligibility\n",
    "    * HS4-year-eligibility\n",
    "    * city-year \n",
    "    * destination-year\n",
    "    * Product-year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideration’s point for the developers/analyst\n",
    "\n",
    "From [Fan et al. - Trade Liberalization, Quality, and Export Prices](https://paperpile.com/app/p/98954695-6715-0f43-ac54-55de0ba1cf20)\n",
    "\n",
    "the majority of the trade literature in defining “quality” as unobserved attributes of a variety that make consumers willing to purchase relatively large quantities of the variety despite relatively high prices charged for the variety\n",
    "we estimate the “effective quality” (quality as it enters consumer’s utility) of exported product $h$ shipped to destination country $c$ by firm $f$ in year $t$,$\\left( q _ { f h c t } \\right) ^ { \\eta }$ via the empirical demand equation:\n",
    "\n",
    "$$x _ { f h c t } = q _ { f h c t } ^ { \\eta } p _ { f h c t } ^ { - \\sigma } P _ { c t } ^ { \\sigma - 1 } Y _ { c t }$$\n",
    "\n",
    "\n",
    "Where $x _ { f h c t }$ denotes the demand for a particular firm $f$’s product\n",
    "\n",
    "We take logs of the empirical demand equation, and then use the residual from the following OLS regression to infer quality: \n",
    "\n",
    "$$\\ln \\left( x _ { f h c t } \\right) + \\sigma \\ln \\left( p _ { f h c t } \\right) = \\varphi _ { h } + \\varphi _ { c t } + \\epsilon _ { f h c t }$$\n",
    "\n",
    "where the country-year fixed effect $\\varphi _ { c t }$ collects both the destination price index $P_{ct}$ and income $Y_{ct}$. The product fixed effect $\\varphi _ { h }$ captures the difference in prices and qualitites across product categories due to the inherent characteristics of products.\n",
    "\n",
    "Then estimated quality is $\\ln \\left( \\hat { q } _ { f h c t } \\right) = \\hat { \\epsilon } _ { f h c t }$\n",
    "\n",
    "Consequently, quality-adjusted prices are the observed log prices less estimated effective quality:\n",
    "\n",
    "$$\\ln \\left(\\widetilde{p}_{f h c t}\\right) = \\ln \\left( p _ { f h c t } \\right) - \\ln \\left( \\hat { q } _ { f h c t } \\right)$$ \n",
    "\n",
    "From Khandewal \n",
    "\n",
    "$$\\hat{\\lambda}_{f c d t} \\equiv \\hat{\\epsilon}_{f c h t} /(\\sigma-1)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1/2 Merge and add new variables\n",
    "\n",
    "In the first step, we merge sigma with the dataframe. There are three industries that do no match:\n",
    "\n",
    "- 910\n",
    "- 970\n",
    "- 911\n",
    "\n",
    "|    | _merge    |   Count |    Percent |   Cumulative Count |   Cumulative Percent |\n",
    "|---:|:----------|--------:|-----------:|-------------------:|---------------------:|\n",
    "|  0 | both      | 2406111 | 0.994417   |            2406111 |             0.994417 |\n",
    "|  1 | left_only |   13509 | 0.00558311 |            2419620 |             1        |\n",
    "\n",
    "We also compute the following variables:\n",
    "\n",
    "- $ \\text{sigma_price} = \\sigma \\ln \\left( \\text{unit_price} \\right)$ \n",
    "- $y = \\ln Quantity + \\text{sigma_price}$\n",
    "- $\\text{FE_ct} = \\varphi _ { c t }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality = (\n",
    "    df_vat.assign(\n",
    "    HS3 = lambda x: x['HS6'].str[:3],\n",
    "    HS4 = lambda x: x['HS6'].str[:4],\n",
    "        \n",
    ")\n",
    "    .merge(sigmas, how = 'inner')\n",
    "    .assign(\n",
    "        sigma_price = lambda x: x['sigma'].astype('float') * np.log(x['unit_price']),\n",
    "        y = lambda x : np.log(x['Quantity']) + x['sigma_price']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality[\"FE_ct\"] = pd.factorize(df_quality[\"year\"] + \n",
    "                                   df_quality[\"Country_en\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: compute the residual and quality\n",
    "\n",
    "The formula is:\n",
    "\n",
    "$$\\ln \\left( y _ { f h c t } \\right)  = \\varphi _ { h } + \\varphi _ { c t } + \\epsilon _ { f h c t }$$\n",
    "\n",
    "There are two quality:\n",
    "\n",
    "1. Price adjusted: $\\ln \\left( p _ { f h c t } \\right) - \\ln \\left( \\hat { q } _ { f h c t } \\right)$\n",
    "2. Khandelwal: $\\hat{\\epsilon}_{f c h t} /(\\sigma-1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels.api as sm\n",
    "#import statsmodels.formula.api as smf\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_proc = make_pipeline(\n",
    "    OneHotEncoder()\n",
    ")\n",
    "preprocessor = make_column_transformer(\n",
    "    (cat_proc, tuple(['HS6', 'FE_ct']))\n",
    ")\n",
    "clf = make_pipeline(preprocessor,\n",
    "                    LinearRegression(fit_intercept=True, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 6m to compute the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MODEL = clf.fit(df_quality[['HS6', 'FE_ct']], df_quality['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_class = MODEL.predict(df_quality[['HS6', 'FE_ct']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality = df_quality.assign(\n",
    "    prediction = lambda x: MODEL.predict(x[['HS6', 'FE_ct']]),\n",
    "    residual = lambda x: x['y'] - x['prediction'],\n",
    "    price_adjusted_quality = lambda x: np.log(x['unit_price']) - x['residual'],\n",
    "    kandhelwal_quality = lambda x: x['residual'] / (x['sigma'].astype('float') -1)\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the following fixed effect for the baseline regression:\n",
    "\n",
    "* firm-product-regime\n",
    "* HS4-year-regime\n",
    "* city-year \n",
    "* destination-year\n",
    "* Product-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### city-product\n",
    "df_quality[\"FE_ck\"] = pd.factorize(df_quality[\"geocode4_corr\"].astype('str') + \n",
    "                                    df_quality[\"HS6\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "### City-sector-year\n",
    "df_quality[\"FE_cst\"] = pd.factorize(df_quality[\"geocode4_corr\"].astype('str') + \n",
    "                                    df_quality[\"HS4\"].astype('str') +\n",
    "                                    df_quality[\"year\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "### City-product-regime\n",
    "df_quality[\"FE_ckr\"] = pd.factorize(df_quality[\"geocode4_corr\"].astype('str') + \n",
    "                                    df_quality[\"HS6\"].astype('str') +\n",
    "                                    df_quality[\"regime\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "### City-sector-regime-year\n",
    "df_quality[\"FE_csrt\"] = pd.factorize(df_quality[\"geocode4_corr\"].astype('str') + \n",
    "                                    df_quality[\"HS4\"].astype('str') +\n",
    "                                    df_quality[\"regime\"].astype('str') +\n",
    "                                    df_quality[\"year\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "## Product-year\n",
    "df_quality[\"FE_kt\"] = pd.factorize(df_quality[\"HS6\"].astype('str') + \n",
    "                                    df_quality[\"year\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "## Product-destination\n",
    "df_quality[\"FE_pj\"] = pd.factorize(df_quality[\"HS6\"].astype('str') + \n",
    "                                    df_quality[\"Country_en\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "## Destination-year\n",
    "df_quality[\"FE_jt\"] = pd.factorize(df_quality[\"Country_en\"].astype('str') + \n",
    "                                    df_quality[\"year\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "#df_quality[\"FE_ct\"] = pd.factorize(df_quality[\"geocode4_corr\"].astype('str') + \n",
    "#                                    df_quality[\"year\"].astype('str')\n",
    "#                                   )[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex = [\n",
    "    'cityen', 'geocode4_corr', 'year', 'regime',\n",
    "    'HS6','HS4','HS3',\n",
    "    'Country_en','ISO_alpha',\n",
    "    'Quantity', 'value', 'unit_price', \n",
    "    'kandhelwal_quality','price_adjusted_quality',\n",
    "    'lag_tax_rebate', 'ln_lag_tax_rebate', 'lag_import_tax', 'ln_lag_import_tax', \n",
    "    'sigma', 'sigma_price', 'y', 'prediction', 'residual', \n",
    "    'FE_ck','FE_cst','FE_ckr', 'FE_csrt', 'FE_kt', 'FE_pj', 'FE_jt', 'FE_ct',\n",
    "    #'FE_ct', 'FE_fpr', 'FE_str','FE_dt', 'FE_pt'\n",
    "]\n",
    "\n",
    "df_quality = df_quality.reindex(columns = reindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to cloud\n",
    "\n",
    "The dataset is ready to be shared with your colleagues. \n",
    "\n",
    "## Output \n",
    "\n",
    "- Filename: quality_vat_export_2003_2010\n",
    "- Link: https://console.cloud.google.com/bigquery?project=valid-pagoda-132423&p=valid-pagoda-132423&d=China&t=quality_vat_export_2003_2010&page=table\n",
    "- Cloud Storage: \n",
    "- Type:  Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality.to_csv('quality_vat_export_2003_2010.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'chinese_data'\n",
    "destination_blob_name = 'paper_project/Processed'\n",
    "source_file_name = 'quality_vat_export_2003_2010.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp.delete_blob(bucket_name, 'paper_project/Processed/quality_vat_export_2003_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp.upload_blob(bucket_name, destination_blob_name, source_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp.delete_table(dataset_name = 'China', name_table = 'quality_vat_export_2003_2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_gcs ='chinese_data/paper_project/Processed/quality_vat_export_2003_2010.csv'\n",
    "gcp.move_to_bq_autodetect(dataset_name= 'China',\n",
    "\t\t\t\t\t\t\t name_table= 'quality_vat_export_2003_2010',\n",
    "\t\t\t\t\t\t\t bucket_gcs=bucket_gcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.move('quality_vat_export_2003_2010.csv',\n",
    "            '../00_Data_catalogue/temporary_local_data/quality_vat_export_2003_2010.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboad Data studio\n",
    "\n",
    "- Name: [Quality_Export_2003_2010](https://datastudio.google.com/u/0/explorer/4721292b-b490-49db-bcdb-2306a2b43aae?config=%7B%22projectId%22:%22valid-pagoda-132423%22,%22tableId%22:%22quality_vat_export_2003_2010%22,%22datasetId%22:%22China%22,%22billingProjectId%22:%22valid-pagoda-132423%22,%22connectorType%22:%22BIG_QUERY%22,%22sqlType%22:%22STANDARD_SQL%22%7D)\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1j7J2vnv1FZaB0iCIVBUKwrWXwo0bm34T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data to catalogue\n",
    "\n",
    "Now that the dataset is ready, you need to add the underlying information to the data catalogue. The data catalogue is stored in [Coda](https://coda.io/d/MasterFile-Database_dvfMWDBnHh8/MetaDatabase_suYFO#_ludIZ), more precisely, in the table named `DataSource`. \n",
    "\n",
    "The cells below helps you to push the information directly to the table using Coda API.\n",
    "\n",
    "The columns are as follow:\n",
    "\n",
    "- `Storage`: Define the location of the table\n",
    "    - GBQ, GS, MongoDB\n",
    "- `Theme`: Define a theme attached to the table\n",
    "    - Accountancy, Complexity, Correspondance, Customer_prediction, Distance, Environment, Finance, Macro, Production, Productivity, Survey, Trade\n",
    "- `Database`: Name of the dataset. Use only for GBQ or MongoDB (collection)\n",
    "    - Business, China, Steamforged, Trade\n",
    "- `Path`:A URL with the path of the location of the dataset\n",
    "- `Filename`: Name of the table\n",
    "- `Description`: Description of the table. Be very specific. \n",
    "- `Source_data`: A list of the data sources used to construct the table.\n",
    "- `Link_methodology`: URL linked to the notebook\n",
    "- `Dataset_documentation`: Github repository attached to the table\n",
    "- `Status`: Status of the table. \n",
    "    - `Closed` if the table won't be altered in the future\n",
    "    - `Active` if the table will be altered in the future\n",
    "- `Profiling`: Specify if the user created a Pandas profiling\n",
    "    - `True` if the profiling has been created\n",
    "    - `False` otherwise\n",
    "- `Profiling_URL`: Profiling URL (link to Github). Always located in `Data_catalogue/table_profiling`\n",
    "- `JupyterStudio`: Specify if the user created a notebook to open the studio\n",
    "    - `True` if the notebook has been created\n",
    "    - `False` otherwise\n",
    "- `JupyterStudio_launcher`: Notebook URL (link to Github). Always located in `Notebooks_Ready_to_use_studio`\n",
    "- `Nb_projects`: Number of projects using this dataset. A Coda formula. Do not update this row\n",
    "- `Created on`: Date of creation. A Coda formula. Do not update this row\n",
    "\n",
    "Remember to commit in GitHub to activate the URL link for the profiling and Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Storage = 'GBQ'\n",
    "Theme = 'Trade' \n",
    "Database = 'China'\n",
    "Description = \"The table is related to the paper that studies the effect of industrial policy in China, the VAT export tax, on the quality upgrading. We use Chinese transaction data for 2002-2006 to isolate the causal impact of the exogenous variation of VAT refund tax and within firm-product change in HS6 exported quality products.\"\n",
    "Filename = 'quality_vat_export_2003_2010'\n",
    "Status = 'Active'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell pushes the information to [Coda](https://coda.io/d/MasterFile-Database_dvfMWDBnHh8/Test-API_suDBp#API_tuDK4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"(.*)/(.*)\"\n",
    "path = os.getcwd()\n",
    "parent_path = Path(path).parent\n",
    "test_str = str(parent_path)\n",
    "matches = re.search(regex, test_str)\n",
    "github_repo = matches.group(2)\n",
    "Source_data = ['VAT_export_2002_2010', 'Sigmas_3digit_China', 'city_cn_en']\n",
    "\n",
    "Profiling = True\n",
    "if Profiling:\n",
    "    Profiling_URL = 'http://htmlpreview.github.io/?https://github.com/' \\\n",
    "    'thomaspernet/{}/blob/master/Data_catalogue/table_profiling/{}.html'.format(github_repo,\n",
    "                                                                               Filename)\n",
    "else:\n",
    "    Profiling_URL = ''\n",
    "JupyterStudio = False\n",
    "if JupyterStudio:\n",
    "    JupyterStudio_URL = '\"https://mybinder.org/v2/gh/thomaspernet/{0}/' \\\n",
    "    'master?filepath=Notebooks_Ready_to_use_studio%2F{1}_studio.ipynb'.format(github_repo, Filename)\n",
    "else:\n",
    "    JupyterStudio_URL = ''\n",
    "### BigQuery only \n",
    "path_url = 'https://console.cloud.google.com/bigquery?project=valid-pagoda-132423' \\\n",
    "'&p=valid-pagoda-132423&d=China&t={}&page=table'.format(Filename)\n",
    "\n",
    "Link_methodology = 'https://nbviewer.jupyter.org/github/thomaspernet/' \\\n",
    "    '{0}/blob/master/Data_preprocessing/' \\\n",
    "    '{1}.ipynb'.format(github_repo,\n",
    "    Filename)\n",
    "\n",
    "Dataset_documentation = 'https://github.com/thomaspernet/{}'.format(github_repo)\n",
    "\n",
    "to_add = {\n",
    "    'Storage': Storage,\n",
    "    'Theme': Theme,\n",
    "    'Database': Database,\n",
    "    'Path_url': path_url,\n",
    "    'Filename': Filename,\n",
    "    'Description': Description,\n",
    "    'Source_data': Source_data,\n",
    "    'Link_methodology': Link_methodology,\n",
    "    'Dataset_documentation': Dataset_documentation,\n",
    "    'Status': Status,\n",
    "    'Profiling_URL': Profiling_URL,\n",
    "    'JupyterStudio_launcher': JupyterStudio_URL\n",
    "\n",
    "}\n",
    "cols= []\n",
    "for key, value in to_add.items():\n",
    "    coda = {\n",
    "    'column': key,\n",
    "    'value':value\n",
    "    }\n",
    "    cols.append(coda)\n",
    "    \n",
    "###load token coda\n",
    "with open('token_coda.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "token = data[0]['token'] \n",
    "\n",
    "uri = f'https://coda.io/apis/v1beta1/docs/vfMWDBnHh8/tables/grid-HgpAnIEhpP/rows'\n",
    "headers = {'Authorization': 'Bearer {}'.format(token)}\n",
    "payload = {\n",
    "  'rows': [\n",
    "    {\n",
    "      'cells': cols,\n",
    "    },\n",
    "  ],\n",
    "}\n",
    "req = requests.post(uri, headers=headers, json=payload)\n",
    "req.raise_for_status() # Throw if there was an error.\n",
    "res = req.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
