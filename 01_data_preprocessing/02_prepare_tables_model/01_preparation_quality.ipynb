{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation quality from Khandelwal methodology\n",
    "\n",
    "This notebook has been generated on 08/14/2020\n",
    "\n",
    "## Objective(s)\n",
    "\n",
    "*  Compute Kandhelwal quality for the table created in the Epic 1, US 2. The quality is computed at the city product-destination-level for each year in our sample.\n",
    "* The notebook was already prepared. Originally, we used the data from BigQuery. \n",
    "* Please, update the Source URL by clicking on the button after the information have been pasted\n",
    "  * US 02 create baseline tables Modify rows\n",
    "  * Delete tables and Github related to the US: Delete rows\n",
    "  \n",
    "# Metadata\n",
    "\n",
    "* Epic: Epic 1\n",
    "* US: US 2\n",
    "* Date Begin: 9/25/2020\n",
    "* Duration Task: 1\n",
    "* Description: Compute the quality of exported products using the export trade table\n",
    "* Status: Active\n",
    "  * Change Status task: Active\n",
    "  * Update table: Modify rows\n",
    "* Source URL: US 02 create baseline tables\n",
    "* Task type: Jupyter Notebook\n",
    "* Users: Thomas Pernet\n",
    "* Watchers: Thomas Pernet\n",
    "* User Account: https://468786073381.signin.aws.amazon.com/console\n",
    "* Estimated Log points: 10\n",
    "* Task tag: #computation,#s3,#machine-learning\n",
    "* Toggl Tag: #data-preparation\n",
    "\n",
    "# Input Cloud Storage [AWS/GCP]\n",
    "\n",
    "If link from the internet, save it to the cloud first\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* Athena\n",
    "* Name: \n",
    "* VAT_export_2003_2010\n",
    "* sigma_industry\n",
    "* Github: \n",
    "    * [00_preparation_baseline_db](https://github.com/thomaspernet/VAT_rebate_quality_china/blob/master/01_data_preprocessing/02_prepare_tables_model/00_preparation_baseline_db.md)\n",
    "    * [01_tables_trade_tariffs_taxes](https://github.com/thomaspernet/VAT_rebate_quality_china/blob/master/01_data_preprocessing/01_prepare_tables/01_tables_trade_tariffs_taxes.md)\n",
    "\n",
    "# Destination Output/Delivery\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* S3\n",
    "* Name:\n",
    "* TRADE_DATA/TRANSFORMED\n",
    "* GitHub:\n",
    "  *  [01_preparation_quality](https://github.com/thomaspernet/VAT_rebate_quality_china/blob/master/01_data_preprocessing/02_prepare_tables_model/01_preparation_quality.md)\n",
    "* URL: \n",
    "* vat-rebate-quality/DATA/TRANSFORMED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "## inputs\n",
    "\n",
    "- Filename: Sigmas_3digit_China\n",
    "- Link: https://docs.google.com/spreadsheets/d/1YLr4n2xLWKIxYftf8ODSMw6tsoiukLMxs1L5mopTDfk/edit?usp=sharing\n",
    "- Type: Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, shutil, json\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'thomas_vat_credentials.csv'\n",
    "region = 'eu-west-3'\n",
    "bucket = 'chinese-data'\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = True) \n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types\n",
    "\n",
    "## Load Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'chinese_trade'\n",
    "table = 'sigma_industry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccode': 'string', 'cname': 'string', 'sigma': 'float', 'hs3': 'string'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )\n",
    "dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM chinese_trade.sigma_industry\n",
    "\"\"\"\n",
    "sigma = (s3.run_query(\n",
    "    query=query,\n",
    "    database=db,\n",
    "    s3_output='SQL_OUTPUT_ATHENA',\n",
    "    filename='sigma',  # Add filename to print dataframe\n",
    "    destination_key=None,  # Add destination key if need to copy output\n",
    "    dtype = dtypes\n",
    ")\n",
    "        )\n",
    "    #.assign(\n",
    "    #hs3_string=lambda x: np.where(\n",
    "    #    x['hs3'].astype('string').str.len() < 3,\n",
    "    #    \"0\" + x['hs3'].astype('string'),\n",
    "    #    x['hs3'].astype('string')\n",
    "    #)\n",
    "#)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ccode     string\n",
       "cname     string\n",
       "sigma    float64\n",
       "hs3       string\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cityen': 'string',\n",
       " 'geocode4_corr': 'string',\n",
       " 'year': 'string',\n",
       " 'regime': 'string',\n",
       " 'hs6': 'string',\n",
       " 'country_en': 'string',\n",
       " 'iso_alpha': 'string',\n",
       " 'quantity': 'float',\n",
       " 'value': 'float',\n",
       " 'unit_price': 'float',\n",
       " 'lag_tax_rebate': 'float',\n",
       " 'ln_lag_tax_rebate': 'float',\n",
       " 'lag_import_tax': 'float',\n",
       " 'ln_lag_import_tax': 'float'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = 'VAT_export_2003_2010'\n",
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )\n",
    "dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM chinese_trade.VAT_export_2003_2010 \n",
    "            \"\"\"\n",
    "df_vat = s3.run_query(\n",
    "    query=query,\n",
    "    database=\"chinese_trade\",\n",
    "    s3_output=\"SQL_OUTPUT_ATHENA\",\n",
    "    filename=\"trade_vat\",  # Add filename to print dataframe\n",
    "    destination_key=None,  # Add destination key if need to copy output\n",
    "    dtype=dtypes,\n",
    ")\n",
    "# .assign(\n",
    "# hs6_string=lambda x: np.where(\n",
    "#    x['hs6'].astype('string').str.len() < 6,\n",
    "#    \"0\" + x['hs6'].astype('string'),\n",
    "#    x['hs6'].astype('string')\n",
    "# )\n",
    "# )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cityen                string\n",
       "geocode4_corr         string\n",
       "year                  string\n",
       "regime                string\n",
       "hs6                   string\n",
       "country_en            string\n",
       "iso_alpha             string\n",
       "quantity             float64\n",
       "value                float64\n",
       "unit_price           float64\n",
       "lag_tax_rebate       float64\n",
       "ln_lag_tax_rebate    float64\n",
       "lag_import_tax       float64\n",
       "ln_lag_import_tax    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_vat.to_csv('../00_Data_catalogue/temporary_local_data/VAT_export_2003_2010.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "1. Merge Sigma\n",
    "2. Create additional variables:\n",
    "    - sigma_price = sigma * log(unit price)\n",
    "    - y = log quantity + sigma_price\n",
    "    - FE_ct = country year fixed effect\n",
    "3. Compute the residual\n",
    "4. Compute quality:\n",
    "    - Adjusted: log(unit price) - residual\n",
    "    - Kandhelwal : residual /(sigma - 1)\n",
    "5. Add Fixed effect\n",
    "    * Name\n",
    "    * firm-product-eligibility\n",
    "    * HS4-year-eligibility\n",
    "    * city-year \n",
    "    * destination-year\n",
    "    * Product-year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideration’s point for the developers/analyst\n",
    "\n",
    "From [Fan et al. - Trade Liberalization, Quality, and Export Prices](https://paperpile.com/app/p/98954695-6715-0f43-ac54-55de0ba1cf20)\n",
    "\n",
    "the majority of the trade literature in defining “quality” as unobserved attributes of a variety that make consumers willing to purchase relatively large quantities of the variety despite relatively high prices charged for the variety\n",
    "we estimate the “effective quality” (quality as it enters consumer’s utility) of exported product $h$ shipped to destination country $c$ by firm $f$ in year $t$,$\\left( q _ { f h c t } \\right) ^ { \\eta }$ via the empirical demand equation:\n",
    "\n",
    "$$x _ { f h c t } = q _ { f h c t } ^ { \\eta } p _ { f h c t } ^ { - \\sigma } P _ { c t } ^ { \\sigma - 1 } Y _ { c t }$$\n",
    "\n",
    "\n",
    "Where $x _ { f h c t }$ denotes the demand for a particular firm $f$’s product\n",
    "\n",
    "We take logs of the empirical demand equation, and then use the residual from the following OLS regression to infer quality: \n",
    "\n",
    "$$\\ln \\left( x _ { f h c t } \\right) + \\sigma \\ln \\left( p _ { f h c t } \\right) = \\varphi _ { h } + \\varphi _ { c t } + \\epsilon _ { f h c t }$$\n",
    "\n",
    "where the country-year fixed effect $\\varphi _ { c t }$ collects both the destination price index $P_{ct}$ and income $Y_{ct}$. The product fixed effect $\\varphi _ { h }$ captures the difference in prices and qualitites across product categories due to the inherent characteristics of products.\n",
    "\n",
    "Then estimated quality is $\\ln \\left( \\hat { q } _ { f h c t } \\right) = \\hat { \\epsilon } _ { f h c t }$\n",
    "\n",
    "Consequently, quality-adjusted prices are the observed log prices less estimated effective quality:\n",
    "\n",
    "$$\\ln \\left(\\widetilde{p}_{f h c t}\\right) = \\ln \\left( p _ { f h c t } \\right) - \\ln \\left( \\hat { q } _ { f h c t } \\right)$$ \n",
    "\n",
    "From Khandewal \n",
    "\n",
    "$$\\hat{\\lambda}_{f c d t} \\equiv \\hat{\\epsilon}_{f c h t} /(\\sigma-1)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1/2 Merge and add new variables\n",
    "\n",
    "In the first step, we merge sigma with the dataframe. There are three industries that do no match:\n",
    "\n",
    "- 910\n",
    "- 970\n",
    "- 911\n",
    "\n",
    "|    | _merge    |   Count |    Percent |   Cumulative Count |   Cumulative Percent |\n",
    "|---:|:----------|--------:|-----------:|-------------------:|---------------------:|\n",
    "|  0 | both      | 5058872 | 0.995119   |            5058872 |             0.995119 |\n",
    "|  1 | left_only |   24811 | 0.00488052 |            5083683 |             1        |\n",
    "\n",
    "```\n",
    "temp=  (\n",
    "    df_vat.assign(\n",
    "    hs3_string = lambda x: x['hs6_string'].str[:3],\n",
    "    hs4_string = lambda x: x['hs6_string'].str[:4],\n",
    "        \n",
    ")\n",
    "    .merge(sigma, how = 'left', indicator= True)\n",
    "     \n",
    ")\n",
    "import sidetable\n",
    "print((temp.stb.freq(['_merge']).to_markdown()))\n",
    "```\n",
    "\n",
    "We also compute the following variables:\n",
    "\n",
    "- $ \\text{sigma_price} = \\sigma \\ln \\left( \\text{unit_price} \\right)$ \n",
    "- $y = \\ln Quantity + \\text{sigma_price}$\n",
    "- $\\text{FE_ct} = \\varphi _ { c t }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality = (\n",
    "    df_vat.assign(\n",
    "    hs3_string = lambda x: x['hs6_string'].str[:3],\n",
    "    hs4_string = lambda x: x['hs6_string'].str[:4],\n",
    "        \n",
    ")\n",
    "    .merge(sigma, how = 'inner')\n",
    "    .assign(\n",
    "        sigma_price = lambda x: x['sigma'].astype('float') * np.log(x['unit_price']),\n",
    "        y = lambda x : np.log(x['quantity']) + x['sigma_price']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality[\"FE_ct\"] = pd.factorize(df_quality[\"year\"].astype('string') + \n",
    "                                   df_quality[\"country_en\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: compute the residual and quality\n",
    "\n",
    "The formula is:\n",
    "\n",
    "$$\\ln \\left( y _ { f h c t } \\right)  = \\varphi _ { h } + \\varphi _ { c t } + \\epsilon _ { f h c t }$$\n",
    "\n",
    "There are two quality:\n",
    "\n",
    "1. Price adjusted: $\\ln \\left( p _ { f h c t } \\right) - \\ln \\left( \\hat { q } _ { f h c t } \\right)$\n",
    "2. Khandelwal: $\\hat{\\epsilon}_{f c h t} /(\\sigma-1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_proc = make_pipeline(\n",
    "    OneHotEncoder()\n",
    ")\n",
    "preprocessor = make_column_transformer(\n",
    "    (cat_proc, tuple(['hs6_string', 'FE_ct']))\n",
    ")\n",
    "clf = make_pipeline(preprocessor,\n",
    "                    LinearRegression(fit_intercept=True, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 6m to compute the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MODEL = clf.fit(df_quality[['hs6_string', 'FE_ct']], df_quality['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_class = MODEL.predict(df_quality[['HS6', 'FE_ct']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality = df_quality.assign(\n",
    "    prediction = lambda x: MODEL.predict(x[['hs6_string', 'FE_ct']]),\n",
    "    residual = lambda x: x['y'] - x['prediction'],\n",
    "    price_adjusted_quality = lambda x: np.log(x['unit_price']) - x['residual'],\n",
    "    kandhelwal_quality = lambda x: x['residual'] / (x['sigma'].astype('float') -1)\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the following fixed effect for the baseline regression:\n",
    "\n",
    "* firm-product-regime\n",
    "* HS4-year-regime\n",
    "* city-year \n",
    "* destination-year\n",
    "* Product-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### city-product\n",
    "df_quality[\"FE_ck\"] = pd.factorize(df_quality[\"geocode4_corr\"].astype('str') + \n",
    "                                    df_quality[\"hs6_string\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "### City-sector-year\n",
    "df_quality[\"FE_cst\"] = pd.factorize(df_quality[\"geocode4_corr\"].astype('str') + \n",
    "                                    df_quality[\"hs4_string\"].astype('str') +\n",
    "                                    df_quality[\"year\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "### City-product-regime\n",
    "df_quality[\"FE_ckr\"] = pd.factorize(df_quality[\"geocode4_corr\"].astype('str') + \n",
    "                                    df_quality[\"hs6_string\"].astype('str') +\n",
    "                                    df_quality[\"regime\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "### City-sector-regime-year\n",
    "df_quality[\"FE_csrt\"] = pd.factorize(df_quality[\"geocode4_corr\"].astype('str') + \n",
    "                                    df_quality[\"hs4_string\"].astype('str') +\n",
    "                                    df_quality[\"regime\"].astype('str') +\n",
    "                                    df_quality[\"year\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "## Product-year\n",
    "df_quality[\"FE_kt\"] = pd.factorize(df_quality[\"hs6_string\"].astype('str') + \n",
    "                                    df_quality[\"year\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "## Product-destination\n",
    "df_quality[\"FE_pj\"] = pd.factorize(df_quality[\"hs6_string\"].astype('str') + \n",
    "                                    df_quality[\"country_en\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "## Destination-year\n",
    "df_quality[\"FE_jt\"] = pd.factorize(df_quality[\"country_en\"].astype('str') + \n",
    "                                    df_quality[\"year\"].astype('str')\n",
    "                                   )[0]\n",
    "\n",
    "#df_quality[\"FE_ct\"] = pd.factorize(df_quality[\"geocode4_corr\"].astype('str') + \n",
    "#                                    df_quality[\"year\"].astype('str')\n",
    "#                                   )[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality['kandhelwal_quality'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex = [\n",
    "    'cityen', 'geocode4_corr', 'year', 'regime',\n",
    "    'hs6_string','hs4_string','hs3_string',\n",
    "    'Country_en','ISO_alpha',\n",
    "    'Quantity', 'value', 'unit_price', \n",
    "    'kandhelwal_quality','price_adjusted_quality',\n",
    "    'lag_tax_rebate', 'ln_lag_tax_rebate', 'lag_import_tax', 'ln_lag_import_tax', \n",
    "    'sigma', 'sigma_price', 'y', 'prediction', 'residual', \n",
    "    'FE_ck','FE_cst','FE_ckr', 'FE_csrt', 'FE_kt', 'FE_pj', 'FE_jt', 'FE_ct',\n",
    "    #'FE_ct', 'FE_fpr', 'FE_str','FE_dt', 'FE_pt'\n",
    "]\n",
    "\n",
    "df_quality = df_quality.reindex(columns = reindex).rename(columns  = {\n",
    "    'hs6_string' : 'HS6',\n",
    "    'hs4_string' : 'HS4',\n",
    "    'hs3_string' : 'HS3',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to cloud\n",
    "\n",
    "The dataset is ready to be shared with your colleagues. \n",
    "\n",
    "## Output \n",
    "\n",
    "- Filename: quality_vat_export_2003_2010\n",
    "- Link: https://s3.console.aws.amazon.com/s3/buckets/vat-rebate-quality/DATA/TRANSFORMED/?region=eu-west-3#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality.to_csv('quality_vat_export_2003_2010.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = 'vat-rebate-quality', verbose = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "'quality_vat_export_2003_2010.csv',\n",
    "    'DATA/TRANSFORMED'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "os.remove('quality_vat_export_2003_2010.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboad Data studio\n",
    "\n",
    "- Name: [Quality_Export_2003_2010](https://datastudio.google.com/u/0/explorer/4721292b-b490-49db-bcdb-2306a2b43aae?config=%7B%22projectId%22:%22valid-pagoda-132423%22,%22tableId%22:%22quality_vat_export_2003_2010%22,%22datasetId%22:%22China%22,%22billingProjectId%22:%22valid-pagoda-132423%22,%22connectorType%22:%22BIG_QUERY%22,%22sqlType%22:%22STANDARD_SQL%22%7D)\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1j7J2vnv1FZaB0iCIVBUKwrWXwo0bm34T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_quality\n",
    "    .groupby(['year', 'regime'])['kandhelwal_quality']\n",
    "    .mean()\n",
    "    #.unstack(-1)\n",
    "    #.plot\n",
    "    #.line()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
