{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC Estimate baseline regression with full fixed effect and with and without export share covariates\n",
    "\n",
    "# Objective(s)\n",
    "\n",
    "Estimate the baseline regression with the following table:\n",
    "\n",
    "* Table 1: Baseline full fixed effect, no covariates\n",
    "* Table 2: Baseline full fixed effect, with covariates city, regime destination, product\n",
    "* Table 3: Baseline full fixed effect, with covariates city, regime, product\n",
    "\n",
    "# Metadata\n",
    "\n",
    "* Epic: Epic 2\n",
    "* US: US 1\n",
    "* Date Begin: 10/4/2020\n",
    "* Duration Task: 0\n",
    "* Description: Regress the quality index at the city, product, destination and time  on the VAT rebate tax and eligibility and other control variables plus a bunch of fixed effect\n",
    "* Step type:  \n",
    "* Status: Active\n",
    "* Source URL: US 01 Table 1 baseline\n",
    "* Task type: Jupyter Notebook\n",
    "* Users: Thomas Pernet\n",
    "* Watchers: Thomas Pernet\n",
    "* User Account: https://468786073381.signin.aws.amazon.com/console\n",
    "* Estimated Log points: 10\n",
    "* Task tag: #econometrics,#ols,#poc\n",
    "* Toggl Tag: #model-training\n",
    "* Meetings:  \n",
    "* Email Information:  \n",
    "  * thread: Number of threads: 0(Default 0, to avoid display email)\n",
    "  *  \n",
    "\n",
    "# Input Cloud Storage [AWS/GCP]\n",
    "\n",
    "## Table/file\n",
    "\n",
    "* Origin: \n",
    "* Athena\n",
    "* Name: \n",
    "* quality_vat_export_covariate_2003_2010\n",
    "* Github: \n",
    "  * https://github.com/thomaspernet/VAT_rebate_quality_china/blob/master/01_data_preprocessing/02_prepare_tables_model/02_transform_table_baseline_covariates.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connexion server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, shutil\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'thomas_vat_credentials.csv'\n",
    "region = 'eu-west-3'\n",
    "bucket = 'chinese-data'\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'chinese_trade'\n",
    "table = 'quality_vat_export_covariate_2003_2010'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )\n",
    "dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM {}.{}\n",
    "\"\"\".format(db, table)\n",
    "df = (s3.run_query(\n",
    "    query=query,\n",
    "    database=db,\n",
    "    s3_output='SQL_OUTPUT_ATHENA',\n",
    "    filename='',  # Add filename to print dataframe\n",
    "    destination_key=None,  # Add destination key if need to copy output\n",
    "    dtype = dtypes\n",
    ")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import echotorch as etnn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "create_report(extension = \"html\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.23.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
