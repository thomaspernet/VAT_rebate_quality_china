{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# US Name\n",
    "Estimate kandhelwal_quality as a function of  ln_lag_tax_rebate and others variables\n",
    "\n",
    "\n",
    "# Description\n",
    "\n",
    "- Compute fixed effect\n",
    "- Estimate table 1\n",
    "- Estimate table 2\n",
    "- Estimate table 4\n",
    "- Estimate table 5\n",
    "\n",
    "## Variables\n",
    "### Target\n",
    "\n",
    "- kandhelwal_quality\n",
    "\n",
    "### Features\n",
    "\n",
    "- ln_lag_tax_rebate\n",
    "- regime\n",
    "\n",
    "## Complementary information\n",
    "\n",
    "\n",
    "\n",
    "# Metadata\n",
    "\n",
    "- Key: 183_VAT_rebate_quality\n",
    "- Epic: Models\n",
    "- US: \n",
    "- Task tag: #data-analysis\n",
    "- Analytics reports: \n",
    "\n",
    "# Input Cloud Storage\n",
    "\n",
    "## Table/file\n",
    "\n",
    "**Name**\n",
    "\n",
    "- https://github.com/thomaspernet/VAT_rebate_quality_china/blob/master/01_data_preprocessing/02_transform_tables/04_baseline_vat_quantity_covariates.md\n",
    "\n",
    "**Github**\n",
    "\n",
    "- china_vat_quality\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Connexion server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import os, shutil, json\n",
    "import sys\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'financial_dep_SO2_accessKeys.csv'\n",
    "region = 'eu-west-3'\n",
    "bucket = 'datalake-datascience'\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False)\n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    #cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "db = 'chinese_trade'\n",
    "table = 'china_vat_quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)',\n",
    "                         'varchar(3)',\n",
    "                        'varchar(14)', 'varchar(11)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint', 'int', 'float']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "download_data = False\n",
    "filename = 'df_{}'.format(table)\n",
    "full_path_filename = 'SQL_OUTPUT_ATHENA/CSV/{}.csv'.format(filename)\n",
    "path_local = os.path.join(str(Path(path).parent.parent.parent), \n",
    "                              \"00_data_catalog/temporary_local_data\")\n",
    "df_path = os.path.join(path_local, filename + '.csv')\n",
    "if download_data:\n",
    "    \n",
    "    s3 = service_s3.connect_S3(client = client,\n",
    "                          bucket = bucket, verbose = False)\n",
    "    query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM {}.{}\n",
    "    \"\"\".format(db, table)\n",
    "    try:\n",
    "        df = (s3.run_query(\n",
    "            query=query,\n",
    "            database=db,\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename=filename,  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "            dtype = dtypes\n",
    "        )\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "    s3.download_file(\n",
    "        key = full_path_filename\n",
    "    )\n",
    "    shutil.move(\n",
    "        filename + '.csv',\n",
    "        os.path.join(path_local, filename + '.csv')\n",
    "    )\n",
    "    s3.remove_file(full_path_filename)\n",
    "    #df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# compute fixed effect\n",
    "\n",
    "Create the following fixed effect for the baseline regression:\n",
    "\n",
    "**index**\n",
    "\n",
    "* city: `c`\n",
    "* product: `k`\n",
    "* sector: `s`\n",
    "* year: `t`\n",
    "* Destination: `j`\n",
    "* regime: `r`\n",
    "\n",
    "**FE**\n",
    "\n",
    "* city-product: `FE_ck`\n",
    "* City-sector-year: `FE_cst`\n",
    "* City-product-regime: `FE_ckr`\n",
    "* City-sector-regime-year: `FE_csrt`\n",
    "* Product-year: `FE_kt`\n",
    "* Product-destination: `FE_pj`\n",
    "* Destination-year: `FE_jt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "create_fe = False\n",
    "if create_fe:\n",
    "    df = pd.read_csv(os.path.join(path_local, filename + '.csv'), dtype = dtypes)\n",
    "    ### city-product\n",
    "    df[\"fe_ck\"] = pd.factorize(df[\"geocode4_corr\"].astype('str') + \n",
    "                                        df[\"hs6\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ### City-sector-year\n",
    "    df[\"fe_cst\"] = pd.factorize(df[\"geocode4_corr\"].astype('str') + \n",
    "                                        df[\"hs2\"].astype('str') +\n",
    "                                        df[\"year\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ### City-product-regime\n",
    "    df[\"fe_ckr\"] = pd.factorize(df[\"geocode4_corr\"].astype('str') + \n",
    "                                        df[\"hs6\"].astype('str') +\n",
    "                                        df[\"regime\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ### City-sector-regime-year\n",
    "    df[\"fe_csrt\"] = pd.factorize(df[\"geocode4_corr\"].astype('str') + \n",
    "                                        df[\"hs2\"].astype('str') +\n",
    "                                        df[\"regime\"].astype('str') +\n",
    "                                        df[\"year\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ## Product-year\n",
    "    df[\"fe_kt\"] = pd.factorize(df[\"hs6\"].astype('str') + \n",
    "                                        df[\"year\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ## Product-destination\n",
    "    df[\"fe_kj\"] = pd.factorize(df[\"hs6\"].astype('str') + \n",
    "                                        df[\"country_en\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ## Destination-year\n",
    "    df[\"fe_jt\"] = pd.factorize(df[\"country_en\"].astype('str') + \n",
    "                                        df[\"year\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ## city-product-destination\n",
    "    df[\"fe_ckj\"] = pd.factorize(df[\"geocode4_corr\"].astype('str') + \n",
    "                                        df[\"hs6\"].astype('str') + \n",
    "                                        df[\"country_en\"].astype('str')\n",
    "                                       )[0]\n",
    "    df.to_csv(os.path.join(path_local, filename + '.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Schema Latex table\n",
    "\n",
    "To rename a variable, please use the following template:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'XX',\n",
    "    'new':'XX_1'\n",
    "    }\n",
    "```\n",
    "\n",
    "if you need to pass a latex format with `\\`, you need to duplicate it for instance, `\\text` becomes `\\\\text:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'working\\_capital\\_i',\n",
    "    'new':'\\\\text{working capital}_i'\n",
    "    }\n",
    "```\n",
    "\n",
    "Then add it to the key `to_rename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "add_to_dic = False\n",
    "if add_to_dic:\n",
    "    if os.path.exists(\"schema_table.json\"):\n",
    "        os.remove(\"schema_table.json\")\n",
    "        data = {'to_rename':[], 'to_remove':[]}\n",
    "    dic_rename = [\n",
    "        {\n",
    "        'old':'working\\_capital\\_i',\n",
    "        'new':'\\\\text{working capital}_i'\n",
    "        },\n",
    "        {\n",
    "        'old':'periodTRUE',\n",
    "        'new':'\\\\text{period}'\n",
    "        },\n",
    "        {\n",
    "        'old':'tso2\\_mandate\\_c',\n",
    "        'new':'\\\\text{policy mandate}_'\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    data['to_rename'].extend(dic_rename)\n",
    "    with open('schema_table.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import latex.latex_beautify as lb\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "library(tidyverse)\n",
    "library(lfe)\n",
    "#library(lazyeval)\n",
    "library('progress')\n",
    "path = \"../../../utils/latex/table_golatex.R\"\n",
    "source(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get df_path\n",
    "df_final <- read_csv(df_path) %>%\n",
    "mutate_if(is.character, as.factor) %>%\n",
    "    mutate_at(vars(starts_with(\"fe\")), as.factor) %>%\n",
    "mutate(regime = relevel(as.factor(regime), ref='NOT_ELIGIBLE'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "head(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 1:XXX\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Quality}_{c,k,j, t}^{R} &=\\alpha \\ln \\operatorname{VAT} \\operatorname{Export} \\operatorname{tax}_{k, t-1} \\times \\text { Eligibility }^{R} \\\\\n",
    "&+F E_{c,k}^{R}+F E_{c,s,t}^{R}+ F E_{k, t}+\\epsilon_{ck,j, t}^{R}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "* Column 1: Estimate for eligible regime only\n",
    "    * FE: \n",
    "        - city-product: `fe_ck`\n",
    "        - city-sector-year: `fe_cst`\n",
    "        - product-destination: `fe_pj`\n",
    "* Column 2: Estimate for non-eligible regime only\n",
    "    * FE: \n",
    "        - city-product: `fe_ck`\n",
    "        - city-sector-year: `fe_cst`\n",
    "        - product-destination: `fe_pj`\n",
    "* Column 3: Full estimate without product-year FE -> Get two coefficients\n",
    "    * FE: \n",
    "        - city-product-regime: `fe_ckr`\n",
    "        - city-sector-regime-year: `fe_csrt`\n",
    "        - product-destination: `fe_pj`\n",
    "* Column 4: Baseline estimate -> Focus on the coef of interest only\n",
    "    * FE: \n",
    "        - city-product-regime: `fe_ckr`\n",
    "        - city-sector-regime-year: `fe_csrt`\n",
    "        - product-year: `fe_kt`\n",
    "\n",
    "Sector is defined as the GBT 4 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 1\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.tex', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "t_0 <- felm(kandhelwal_quality ~ln_lag_tax_rebate+ ln_lag_import_tax  \n",
    "            | fe_ck + fe_cst+fe_kj|0 | hs6, df_final %>% filter(regime == 'ELIGIBLE'),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "print('table 0 done')\n",
    "t_1 <- felm(kandhelwal_quality ~ln_lag_tax_rebate + ln_lag_import_tax \n",
    "            | fe_ck + fe_cst+fe_kj|0 | hs6, df_final %>% filter(regime != 'ELIGIBLE'),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "print('table 1 done')\n",
    "t_2 <- felm(kandhelwal_quality ~ln_lag_tax_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax\n",
    "            | fe_ckr + fe_csrt + fe_kj|0 | hs6, df_final,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "print('table 2 done')\n",
    "t_3 <- felm(kandhelwal_quality ~ln_lag_tax_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax \n",
    "            | fe_ckr + fe_csrt+fe_kt|0 | hs6, df_final,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "print('table 3 done')\n",
    "t_4 <- felm(kandhelwal_quality ~ln_lag_tax_rebate+ ln_lag_import_tax  \n",
    "            | fe_ck + fe_cst+fe_kj+ fe_ckj|0 | hs6, df_final %>% filter(regime == 'ELIGIBLE'),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "print('table 4 done')\n",
    "t_5 <- felm(kandhelwal_quality ~ln_lag_tax_rebate + ln_lag_import_tax \n",
    "            | fe_ck + fe_cst+fe_kj+ fe_ckj|0 | hs6, df_final %>% filter(regime != 'ELIGIBLE'),\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "print('table 5 done')\n",
    "t_6 <- felm(kandhelwal_quality ~ln_lag_tax_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax\n",
    "            | fe_ckr + fe_csrt + fe_kj+ fe_ckj|0 | hs6, df_final,\n",
    "            exactDOF = TRUE)\n",
    "\n",
    "print('table 6 done')\n",
    "t_7 <- felm(kandhelwal_quality ~ln_lag_tax_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax \n",
    "            | fe_ckr + fe_csrt+fe_kt+ fe_ckj|0 | hs6, df_final,\n",
    "            exactDOF = TRUE)\n",
    "            \n",
    "dep <- \"Dependent variable: Product quality\"\n",
    "fe1 <- list(\n",
    "    c(\"City-product fixed effects\", \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\"),\n",
    "    \n",
    "    c(\"City-sector-year fixed effects\", \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\"),\n",
    "    \n",
    "    c(\"Product-destination fixed effect\",\"Yes\", \"Yes\", \"Yes\", \"No\",\"Yes\", \"Yes\", \"Yes\", \"No\"),\n",
    "    \n",
    "    c(\"City-product-regime fixed effects\",\"No\", \"No\", \"Yes\", \"Yes\",\"No\", \"No\", \"Yes\", \"Yes\"),\n",
    "    \n",
    "    c(\"City-sector-regime-year fixed effects\",\"No\", \"No\", \"Yes\", \"Yes\",\"No\", \"No\", \"Yes\", \"Yes\"),\n",
    "    \n",
    "    c(\"Product-year fixed effects\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\"),\n",
    "    \n",
    "    c(\"City-product-destination fixed effects\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\")\n",
    "    \n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3, t_4, t_5, t_6, t_7\n",
    "),\n",
    "    title=\"VAT export tax and product's quality upgrading, baseline regression\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"This table estimates eq(3). \" \\\n",
    "\"Note that 'Eligible' refers to the regime entitle to VAT refund, our treatment group.\" \\\n",
    "\"Our control group is processing trade with supplied input, 'Non-Eligible' to VAT refund.\" \\\n",
    "\"Sectors are defined following the Chinese 4-digit GB/T industry\" \\\n",
    "\"classification and regroup several products.\" \\\n",
    "\"Heteroskedasticity-robust standard errors\" \\\n",
    "\"clustered at the product level appear inparentheses.\"\\\n",
    "\"\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\"\n",
    "\n",
    "multicolumn ={\n",
    "    'Eligible': 1,\n",
    "    'Non-Eligible': 1,\n",
    "    'All': 1,\n",
    "    'All benchmark': 1,\n",
    "    'Eligible': 1,\n",
    "    'Non-Eligible': 1,\n",
    "    'All': 1,\n",
    "    'All benchmark': 1,\n",
    "}\n",
    "\n",
    "multi_lines_dep = '(city/product/trade regime/year)'\n",
    "#new_r = ['& test1', 'test2']\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "            multi_lines_dep = multi_lines_dep,\n",
    "            #new_row= new_r,\n",
    "            multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 150,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp\n",
    "import make_toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False, notebookname = None):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            notebookname = notebookname  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "create_report(extension = \"html\", keep_code = False, notebookname = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Update TOC in Github\n",
    "for p in [parent_path, path, str(Path(path).parent), os.path.join(str(Path(path).parent), \"00_download_data_from\")]:\n",
    "    try:\n",
    "        os.remove(os.path.join(p, 'README.md'))\n",
    "    except:\n",
    "        pass\n",
    "    path_parameter = os.path.join(parent_path,'utils', 'parameters_ETL_Financial_dependency_pollution.json')\n",
    "    md_lines =  make_toc.create_index(cwd = p, path_parameter = path_parameter)\n",
    "    md_out_fn = os.path.join(p,'README.md')\n",
    "    \n",
    "    if p == parent_path:\n",
    "    \n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = True, path_parameter = path_parameter)\n",
    "    else:\n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nteract": {
   "version": "0.26.0"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ],
    [
     "python3",
     "python3",
     "python",
     "",
     ""
    ]
   ],
   "version": "0.20.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
