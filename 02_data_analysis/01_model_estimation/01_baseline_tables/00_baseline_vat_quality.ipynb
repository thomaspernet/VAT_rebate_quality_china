{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# US Name\n",
    "Estimate kandhelwal_quality as a function of  ln_lag_tax_rebate and others variables\n",
    "\n",
    "\n",
    "# Description\n",
    "\n",
    "- Change sign for story\n",
    "- Check sign price adjusted\n",
    "- Estimate table 1\n",
    "- Estimate table 2\n",
    "- Estimate table 4\n",
    "- Estimate table 5\n",
    "\n",
    "## Variables\n",
    "### Target\n",
    "\n",
    "kandhelwal_quality\n",
    "\n",
    "### Features\n",
    "\n",
    "- ln_lag_tax_rebate\n",
    "- regime\n",
    "- ln_lag_import_tax\n",
    "\n",
    "## Complementary information\n",
    "\n",
    "\n",
    "\n",
    "# Metadata\n",
    "\n",
    "- Key: 198_VAT_rebate_quality\n",
    "- Epic: Models\n",
    "- US: Baseline table\n",
    "- Task tag: #data-analysis\n",
    "- Analytics reports: \n",
    "\n",
    "# Input Cloud Storage\n",
    "\n",
    "## Table/file\n",
    "\n",
    "**Name**\n",
    "\n",
    "- china_vat_quality\n",
    "\n",
    "**Github**\n",
    "\n",
    "- https://github.com/thomaspernet/VAT_rebate_quality_china/blob/master/01_data_preprocessing/02_transform_tables/04_baseline_vat_quantity_covariates.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Connexion server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "from awsPy.aws_authorization import aws_connector\n",
    "from awsPy.aws_s3 import service_s3\n",
    "from awsPy.aws_glue import service_glue\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import os, shutil, json\n",
    "import sys\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "\n",
    "\n",
    "name_credential = 'financial_dep_SO2_accessKeys.csv'\n",
    "region = 'eu-west-3'\n",
    "bucket = 'datalake-datascience'\n",
    "path_cred = \"{0}/creds/{1}\".format(parent_path, name_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "con = aws_connector.aws_instantiate(credential = path_cred,\n",
    "                                       region = region)\n",
    "client= con.client_boto()\n",
    "s3 = service_s3.connect_S3(client = client,\n",
    "                      bucket = bucket, verbose = False)\n",
    "glue = service_glue.connect_glue(client = client) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pandas_setting = True\n",
    "if pandas_setting:\n",
    "    #cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "change_target <- function(table){\n",
    "    ## Regime\n",
    "    check_target <- grep(\"regimeELIGIBLE:ln_lag_import_tax\", rownames(table$coef))\n",
    "    \n",
    "    if (length(check_target) !=0) {\n",
    "    ## SOE\n",
    "    rownames(table$coefficients)[check_target] <- 'ln_lag_import_tax:regimeELIGIBLE'\n",
    "    rownames(table$beta)[check_target] <- 'ln_lag_import_tax:regimeELIGIBLE'\n",
    "    } \n",
    "    return (table)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Load tables\n",
    "\n",
    "Since we load the data as a Pandas DataFrame, we want to pass the `dtypes`. We load the schema from Glue to guess the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "db = 'chinese_trade'\n",
    "table = 'china_vat_quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "dtypes = {}\n",
    "schema = (glue.get_table_information(database = db,\n",
    "                           table = table)\n",
    "          ['Table']['StorageDescriptor']['Columns']\n",
    "         )\n",
    "for key, value in enumerate(schema):\n",
    "    if value['Type'] in ['varchar(12)',\n",
    "                         'varchar(3)',\n",
    "                        'varchar(14)', 'varchar(11)']:\n",
    "        format_ = 'string'\n",
    "    elif value['Type'] in ['decimal(21,5)', 'double', 'bigint', 'int', 'float']:\n",
    "        format_ = 'float'\n",
    "    else:\n",
    "        format_ = value['Type'] \n",
    "    dtypes.update(\n",
    "        {value['Name']:format_}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "download_data = False\n",
    "filename = 'df_{}'.format(table)\n",
    "full_path_filename = 'SQL_OUTPUT_ATHENA/CSV/{}.csv'.format(filename)\n",
    "path_local = os.path.join(str(Path(path).parent.parent.parent), \n",
    "                              \"00_data_catalog/temporary_local_data\")\n",
    "df_path = os.path.join(path_local, filename + '.csv')\n",
    "if download_data:\n",
    "    \n",
    "    s3 = service_s3.connect_S3(client = client,\n",
    "                          bucket = bucket, verbose = False)\n",
    "    query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM {}.{}\n",
    "    \"\"\".format(db, table)\n",
    "    try:\n",
    "        df = (s3.run_query(\n",
    "            query=query,\n",
    "            database=db,\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename=filename,  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "            dtype = dtypes\n",
    "        )\n",
    "                )\n",
    "    except:\n",
    "        pass\n",
    "    s3.download_file(\n",
    "        key = full_path_filename\n",
    "    )\n",
    "    shutil.move(\n",
    "        filename + '.csv',\n",
    "        os.path.join(path_local, filename + '.csv')\n",
    "    )\n",
    "    s3.remove_file(full_path_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "lines_to_next_cell": 0
   },
   "source": [
    "# compute fixed effect\n",
    "\n",
    "| Benchmark | Origin            | Name                     | Description                                                                                                                                                                                                                                                                                                                                    | Math_notebook     |\n",
    "|-----------|-------------------|--------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------|\n",
    "| Yes       | Current           | city-product             |                                                                                                                                                                                                                                                                                                                                                | $\\alpha_{ck}$     |\n",
    "| Yes       | Current           | city-product-regime      |                                                                                                                                                                                                                                                                                                                                                | $\\alpha_{ck}^R$   |\n",
    "| Yes       | Current           | city-sector-year         | Sector is defined as GBT 4 digit                                                                                                                                                                                                                                                                                                               | $\\alpha_{cst}$    |\n",
    "| Yes       | Current           | city-sectorãƒ¼regime-year | Sector is defined as GBT 4 digit                                                                                                                                                                                                                                                                                                               | $\\alpha_{cst}^R$  |\n",
    "| Yes       | Current           | product-destination      |                                                                                                                                                                                                                                                                                                                                                | $\\alpha_{pj}$     |\n",
    "| Yes       | Previous baseline | Product-year             | account for all factors that affect product-level export irrespective of the trade regime in a given year                                                                                                                                                                                                                                      | $\\alpha_{pt}$     |\n",
    "| No        | Previous baseline | firm-product-eligibility | captures all the factors that affect firms regardless of the time and type of regime. This firmâ€’product pair eliminates the demand shocks that firms face and that are not correlated with the types of status. The fixed effects are also responsible for potential correlations between subsidies, R&D, or trade policies and VAT rebates.   | $\\alpha^{E}_{it}$ |\n",
    "| No        | Previous baseline | HS4-year-eligibility     |                                                                                                                                                                                                                                                                                                                                                | $\\alpha^{E}_{st}$ |\n",
    "| No        | Previous baseline | city-year                | captures the differences in demand, capital intensity, or labor supply that prevail between cities each year                                                                                                                                                                                                                                   | $\\alpha_{ct}$     |\n",
    "| No        | Candidate         | destination-year         | Captures additional level of control, encompassing all the shocks and developments in the economies to which China exports.                                                                                                                                                                                                                    | $\\alpha_{dt}$     |\n",
    "\n",
    "\n",
    "Create the following fixed effect for the baseline regression:\n",
    "\n",
    "**index**\n",
    "\n",
    "* city: `c`\n",
    "* product: `k`\n",
    "* sector: `s`\n",
    "* year: `t`\n",
    "* Destination: `j`\n",
    "* regime: `r`\n",
    "\n",
    "**FE**\n",
    "\n",
    "* city-product: `FE_ck`\n",
    "* City-sector-year: `FE_cst`\n",
    "* City-product-regime: `FE_ckr`\n",
    "* City-sector-regime-year: `FE_csrt`\n",
    "* Product-year: `FE_kt`\n",
    "* Product-destination: `FE_pj`\n",
    "* Destination-year: `FE_jt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "lines_to_next_cell": 0
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "<!-- #endregion -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "create_fe = False\n",
    "if create_fe:\n",
    "    df = pd.read_csv(df_path, dtype = dtypes)\n",
    "    ### city-product\n",
    "    df[\"fe_ck\"] = pd.factorize(df[\"geocode4_corr\"].astype('str') + \n",
    "                                        df[\"hs6\"].astype('str')\n",
    "                                       )[0]\n",
    "    \n",
    "    ### sector-year\n",
    "    df[\"fe_st\"] = pd.factorize(\n",
    "                                        df[\"hs4\"].astype('str') +\n",
    "                                        df[\"year\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ### sector-year\n",
    "    df[\"fe_ct\"] = pd.factorize(\n",
    "                                        df[\"geocode4_corr\"].astype('str') +\n",
    "                                        df[\"year\"].astype('str')\n",
    "                                       )[0]\n",
    "    \n",
    "    ### City-sector-year\n",
    "    df[\"fe_cst\"] = pd.factorize(df[\"geocode4_corr\"].astype('str') + \n",
    "                                        df[\"hs4\"].astype('str') +\n",
    "                                        df[\"year\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ### City-product-regime\n",
    "    df[\"fe_ckr\"] = pd.factorize(df[\"geocode4_corr\"].astype('str') + \n",
    "                                        df[\"hs6\"].astype('str') +\n",
    "                                        df[\"regime\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ### City-sector-regime-year\n",
    "    df[\"fe_csrt\"] = pd.factorize(df[\"geocode4_corr\"].astype('str') + \n",
    "                                        df[\"hs4\"].astype('str') +\n",
    "                                        df[\"regime\"].astype('str') +\n",
    "                                        df[\"year\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ## Product-year\n",
    "    df[\"fe_kt\"] = pd.factorize(df[\"hs6\"].astype('str') + \n",
    "                                        df[\"year\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ## Product-destination\n",
    "    df[\"fe_kj\"] = pd.factorize(df[\"hs6\"].astype('str') + \n",
    "                                        df[\"country_en\"].astype('str')\n",
    "                                       )[0]\n",
    "\n",
    "    ## Destination-year\n",
    "    df[\"fe_jt\"] = pd.factorize(df[\"country_en\"].astype('str') + \n",
    "                                        df[\"year\"].astype('str')\n",
    "                                       )[0]\n",
    "    \n",
    "    ## Destination-year-regime\n",
    "    df[\"fe_jtr\"] = pd.factorize(df[\"country_en\"].astype('str') + \n",
    "                                        df[\"year\"].astype('str') +\n",
    "                                df[\"regime\"].astype('str')\n",
    "                                \n",
    "                                       )[0]\n",
    "\n",
    "    ## city-product-destination\n",
    "    df[\"fe_ckj\"] = pd.factorize(df[\"geocode4_corr\"].astype('str') + \n",
    "                                        df[\"hs6\"].astype('str') + \n",
    "                                        df[\"country_en\"].astype('str')\n",
    "                                       )[0]\n",
    "    \n",
    "    ## product destination regime \n",
    "    df[\"fe_kjr\"] = pd.factorize(df[\"hs6\"].astype('str') + \n",
    "                                        df[\"country_en\"].astype('str') + \n",
    "                                        df[\"regime\"].astype('str')\n",
    "                                       )[0]\n",
    "    ## Shocks\n",
    "    df[\"fe_group_shock\"] = pd.factorize(\n",
    "        df[\"hs6\"].astype('str') +\n",
    "        df[\"country_en\"].astype('str') + \n",
    "        df[\"year\"].astype('str'))[0]\n",
    "    \n",
    "    df.to_csv(os.path.join(path_local, filename + '.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Schema Latex table\n",
    "\n",
    "To rename a variable, please use the following template:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'XX',\n",
    "    'new':'XX_1'\n",
    "    }\n",
    "```\n",
    "\n",
    "if you need to pass a latex format with `\\`, you need to duplicate it for instance, `\\text` becomes `\\\\text:\n",
    "\n",
    "```\n",
    "{\n",
    "    'old':'working\\_capital\\_i',\n",
    "    'new':'\\\\text{working capital}_i'\n",
    "    }\n",
    "```\n",
    "\n",
    "Then add it to the key `to_rename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "add_to_dic = True\n",
    "if add_to_dic:\n",
    "    if os.path.exists(\"schema_table.json\"):\n",
    "        os.remove(\"schema_table.json\")\n",
    "    data = {'to_rename':[], 'to_remove':[]}\n",
    "    dic_rename = [\n",
    "        {\n",
    "        'old':'ln\\_lag\\_tax\\_rebate',\n",
    "        'new':'\\\\text{Ln VAT export tax}_{k, t-1}'\n",
    "        },\n",
    "        {\n",
    "        'old':'ln\\_rebate',\n",
    "        'new':'\\\\text{Ln VAT rebate}_{k, t-1}'\n",
    "        },\n",
    "        {\n",
    "        'old':'ln\\_rebate\\_1',\n",
    "        'new':'\\\\text{Ln VAT rebate}_{k, t-1}'\n",
    "        },\n",
    "        {\n",
    "        'old':'ln\\_rebate\\_2',\n",
    "        'new':'\\\\text{Ln VAT rebate}_{k, t-1}'\n",
    "        },\n",
    "        {\n",
    "        'old':'regimeELIGIBLE',\n",
    "        'new':'\\\\text{Regime}^R'\n",
    "        },\n",
    "        {\n",
    "        'old':'ln\\_lag\\_import\\_tax',\n",
    "        'new':'\\\\text{Ln VAT import tax,}_{k, t-1}'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_foreign\\_export\\_share\\_ckr',\n",
    "        'new':'\\\\text{lag foreign export share}_{ck, t-1}^R'\n",
    "        },\n",
    "        {\n",
    "        'old':'lag\\_soe\\_export\\_share\\_ckr',\n",
    "        'new':'\\\\text{lag SOE export share}_{ck, t-1}^R'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    data['to_rename'].extend(dic_rename)\n",
    "    with open('schema_table.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import latex.latex_beautify as lb\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "library(tidyverse)\n",
    "library(lfe)\n",
    "#library(lazyeval)\n",
    "library('progress')\n",
    "path = \"../../../utils/latex/table_golatex.R\"\n",
    "source(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get df_path\n",
    "df_final <- read_csv(df_path) %>%\n",
    "mutate_if(is.character, as.factor) %>%\n",
    "    mutate_at(vars(starts_with(\"fe\")), as.factor) %>%\n",
    "mutate(\n",
    "    regime = relevel(as.factor(regime), ref='NOT_ELIGIBLE'),\n",
    "    ln_rebate = ln_lag_tax_rebate * (-1),\n",
    "    ln_rebate_1 = log((lag_vat_reb_m / lag_vat_m) +1),\n",
    "    ln_rebate_2 = log(lag_vat_reb_m + 1)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "head(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 1: baseline estimate\n",
    "\n",
    "$$\\begin{aligned} \\text{Quality}_{c,k,j, t}^{R} &=\\alpha \\ln \\text{VAT Rebate}_{k, t-1} \\times \\text { Eligibility }^{R} +\\alpha \\ln \\text{Import tax} \\times \\text { Eligibility }^{R} +X_{c, s, t-1}^{R}+F E_{c,k}^{R}+F E_{k,t}+F E_{j,t}+\\epsilon_{c,k,j, t}^{R} \\end{aligned} $$\n",
    "\n",
    " \n",
    "Use ln_rebate_1 = log((lag_vat_reb_m / lag_vat_m) +1)  â†’ share of rebate and FE â†’ fe_ckr  + fe_kt + fe_jtr\n",
    "\n",
    "* Baseline estimate\n",
    "* Baseline estimate with more controls\n",
    "* Controlling for product-country-year trends\n",
    "* cities presents all years\n",
    "* Keep rebates 17%\n",
    "* Exclude rebates 0% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#folder = 'Tables_0'\n",
    "#table_nb = 1\n",
    "#table = 'table_{}'.format(table_nb)\n",
    "#path = os.path.join(folder, table + '.txt')\n",
    "#if os.path.exists(folder) == False:\n",
    "#        os.mkdir(folder)\n",
    "#for ext in ['.txt', '.tex', '.pdf']:\n",
    "#    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "#    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "#%get path table\n",
    "### unit price\n",
    "#t_0 <- felm(log(unit_price) ~ln_rebate+ ln_lag_import_tax  \n",
    "#            | fe_ck + fe_cst+fe_kj|0 | hs6, df_final %>% filter(regime == 'ELIGIBLE'),\n",
    "#            exactDOF = TRUE)\n",
    "\n",
    "#print('table 0 done')\n",
    "#t_1 <- felm(log(unit_price) ~ln_rebate + ln_lag_import_tax \n",
    "#            | fe_ck + fe_cst+fe_kj|0 | hs6, df_final %>% filter(regime != 'ELIGIBLE'),\n",
    "#            exactDOF = TRUE)\n",
    "\n",
    "#print('table 1 done')\n",
    "#t_2 <- felm(log(unit_price) ~ln_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax\n",
    "#            | fe_ckr + fe_csrt + fe_kj|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_2 <- change_target(t_2)\n",
    "\n",
    "#print('table 2 done')\n",
    "#t_3 <- felm(log(unit_price) ~ln_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax \n",
    "#            | fe_ckr + fe_csrt+fe_kt|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_3 <- change_target(t_3)\n",
    "\n",
    "#print('table 3 done')\n",
    "#t_4 <- felm(log(unit_price) ~ln_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax +\n",
    "#            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "#            | fe_ckr + fe_csrt + fe_kj|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_4 <- change_target(t_4)\n",
    "#print('table 4 done')\n",
    "#t_5 <- felm(log(unit_price) ~ln_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax +\n",
    "#            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "#            | fe_ckr + fe_csrt+fe_kt|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_5 <- change_target(t_5)\n",
    "#print('table 5 done')\n",
    "\n",
    "#dep <- \"Dependent variable: unit price\"\n",
    "#fe1 <- list(\n",
    "#    c(\"City-product fixed effects\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"No\"\n",
    "#     ),\n",
    "#    \n",
    "#    c(\"City-sector-year fixed effects\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"No\"\n",
    "#     ),\n",
    "#    \n",
    "#    c(\"Product-destination fixed effect\",\"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"No\"\n",
    "#     ),\n",
    "#   \n",
    "#    c(\"City-product-regime fixed effects\",\"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"\n",
    "#     ),\n",
    "#    \n",
    "#    c(\"City-sector-regime-year fixed effects\",\"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"\n",
    "#     ),\n",
    "#    \n",
    "#    c(\"Product-year fixed effects\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"Yes\"\n",
    "#     ),\n",
    "#    \n",
    "#    c(\"City-product-destination fixed effects\", \"No\", \"No\", \"No\", \"No\",\"Yes\", \"Yes\"\n",
    "#     )\n",
    "#    \n",
    "#            )\n",
    "\n",
    "#table_1 <- go_latex(list(\n",
    "#    t_0,t_1, t_2, t_3, t_4, t_5\n",
    "#),\n",
    "#    title=\"VAT export tax and product's unit price, baseline regression\",\n",
    "#    dep_var = dep,\n",
    "#    addFE=fe1,\n",
    "#    save=TRUE,\n",
    "#    note = FALSE,\n",
    "#    name=path\n",
    "#) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#tbe1  = \"This table estimates eq(3). \" \\\n",
    "#\"A positive value of Ln VAT rebate means the product has lower tax\" \\\n",
    "#\"Note that 'Eligible' refers to the regime entitle to VAT refund, our treatment group.\" \\\n",
    "#\"Our control group is processing trade with supplied input, 'Non-Eligible' to VAT refund.\" \\\n",
    "#\"Sectors are defined following the Chinese 4-digit GB/T industry\" \\\n",
    "#\"classification and regroup several products.\" \\\n",
    "#\"Heteroskedasticity-robust standard errors\" \\\n",
    "#\"clustered at the product level appear inparentheses.\"\\\n",
    "#\"\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\"\n",
    "\n",
    "#multicolumn ={\n",
    "#    'Eligible': 1,\n",
    "#   'Non-Eligible': 1,\n",
    "#    'All': 1,\n",
    "#    'All benchmark': 1,\n",
    "#    'All': 1,\n",
    "#    'All benchmark': 1,\n",
    "#}\n",
    "\n",
    "#multi_lines_dep = '(city/product/trade regime/year)'\n",
    "#new_r = ['& test1', 'test2']\n",
    "#lb.beautify(table_number = table_nb,\n",
    "            #reorder_var = reorder,\n",
    "#            multi_lines_dep = multi_lines_dep,\n",
    "            #new_row= new_r,\n",
    "#            multicolumn = multicolumn,\n",
    "#            table_nte = tbe1,\n",
    "#            jupyter_preview = True,\n",
    "#            resolution = 150,\n",
    "#            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 1\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "for ext in ['.txt', '.tex', '.pdf']:\n",
    "    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "### Quality\n",
    "#t_0 <- felm(kandhelwal_quality ~ln_rebate_1+ ln_lag_import_tax  \n",
    "#            | fe_ck  + fe_kt + fe_jt|0 | hs6, df_final %>% filter(regime == 'ELIGIBLE'),\n",
    "#            exactDOF = TRUE)\n",
    "\n",
    "#print('table 0 done')\n",
    "#t_1 <- felm(kandhelwal_quality ~ln_rebate_1 + ln_lag_import_tax \n",
    "#            | fe_ck  + fe_kt + fe_jt|0 | hs6, df_final %>% filter(regime != 'ELIGIBLE'),\n",
    "#            exactDOF = TRUE)\n",
    "### all coefs\n",
    "#print('table 1 done')\n",
    "#t_2 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax\n",
    "#            | fe_ck  + fe_kt + fe_jt|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_2 <- change_target(t_2)\n",
    "#print('table 2 done')\n",
    "### focus coef -> benchmark\n",
    "t_0 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax \n",
    "            | fe_ckr  + fe_kt + fe_jtr |0 | hs6, df_final,\n",
    "            exactDOF = TRUE)\n",
    "t_0 <- change_target(t_0)\n",
    "print('table 0 done')\n",
    "\n",
    "t_1 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax +\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final,\n",
    "            exactDOF = TRUE)\n",
    "t_1 <- change_target(t_1)\n",
    "print('table 1 done')\n",
    "\n",
    "t_2 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr + fe_group_shock|0 | hs6, df_final,\n",
    "            exactDOF = TRUE)\n",
    "t_2 <- change_target(t_2)\n",
    "print('table 2 done')\n",
    "\n",
    "t_3 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax +\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% group_by(geocode4_corr) %>%\n",
    "  mutate(length = length(unique(year))) %>%\n",
    "  filter(length ==8),\n",
    "            exactDOF = TRUE)\n",
    "t_3 <- change_target(t_3)\n",
    "print('table 3 done')\n",
    "\n",
    "t_4 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(lag_vat_m==17),\n",
    "            exactDOF = TRUE)\n",
    "t_4 <- change_target(t_4)\n",
    "print('table 4 done')\n",
    "\n",
    "t_5 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(lag_vat_reb_m != 0),\n",
    "            exactDOF = TRUE)\n",
    "t_5 <- change_target(t_5)\n",
    "print('table 5 done')\n",
    "### all coefs + covariates\n",
    "#t_4 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax \n",
    "#            +  lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "#            | fe_ck  + fe_kt + fe_jt|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_4 <- change_target(t_4)\n",
    "#print('table 4 done')\n",
    "\n",
    "### focus coef + covariates\n",
    "\n",
    "#t_6 <- felm(kandhelwal_quality ~ln_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax +\n",
    "#            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "#            | fe_ckr + fe_csrt+fe_ckj + fe_kt|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_6 <- change_target(t_6)\n",
    "#print('table 6 done')\n",
    "\n",
    "### quality-adjusted price is net-quality price\n",
    "#t_6 <- felm(price_adjusted_quality ~ln_rebate_1+ ln_lag_import_tax  \n",
    "#            | fe_ck + fe_cst+fe_kj|0 | hs6, df_final %>% filter(regime == 'ELIGIBLE'),\n",
    "#            exactDOF = TRUE)\n",
    "\n",
    "\n",
    "#print('table 6 done')\n",
    "#t_7 <- felm(price_adjusted_quality ~ln_rebate_1 + ln_lag_import_tax \n",
    "#            | fe_ck + fe_cst+fe_kj|0 | hs6, df_final %>% filter(regime != 'ELIGIBLE'),\n",
    "#            exactDOF = TRUE)\n",
    "\n",
    "#print('table 7 done')\n",
    "#t_8 <- felm(price_adjusted_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax\n",
    "#            | fe_ckr + fe_csrt + fe_kj|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_8 <- change_target(t_8)\n",
    "\n",
    "#print('table 8 done')\n",
    "#t_9 <- felm(price_adjusted_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax \n",
    "#            | fe_ckr + fe_csrt+fe_kt|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_9 <- change_target(t_9)\n",
    "\n",
    "#print('table 9 done')\n",
    "#t_10 <- felm(price_adjusted_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax +\n",
    "#            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "#            | fe_ckr + fe_csrt + fe_kj|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_10 <- change_target(t_10)\n",
    "#print('table 10 done')\n",
    "#t_11 <- felm(price_adjusted_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax +\n",
    "#            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "#            | fe_ckr + fe_csrt+fe_kt|0 | hs6, df_final,\n",
    "#            exactDOF = TRUE)\n",
    "#t_11 <- change_target(t_11)\n",
    "#print('table 11 done')\n",
    "\n",
    "dep <- \"Dependent variable: Product quality\"\n",
    "fe1 <- list(\n",
    "    c(\"City-product-regime\",\n",
    "      \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\",\"Yes\"\n",
    "      #\"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"\n",
    "     ),\n",
    "    \n",
    "    c(\"Product-year\",\n",
    "      \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\",\"Yes\"\n",
    "      #\"No\", \"No\", \"No\", \"Yes\", \"No\", \"Yes\"\n",
    "     ),\n",
    "    \n",
    "    c(\"Destination-year\",\n",
    "      \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\",\"Yes\"\n",
    "      #\"No\", \"No\", \"No\", \"Yes\", \"No\", \"Yes\"\n",
    "     )\n",
    "    \n",
    "    #c(\"City-sector-year\",\n",
    "    #  \"Yes\", \"Yes\", \"No\", \"No\", \"No\"#, \"No\", \"No\", \n",
    "    #  #\"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"No\"\n",
    "    # ),\n",
    "    #c(\"City-product-destination\",\n",
    "    #  \"Yes\", \"Yes\", \"Yes\", \"Yes\",\"Yes\", \"Yes\", \"Yes\"#,\n",
    "    # # \"No\", \"No\", \"No\", \"No\",\"Yes\", \"Yes\"\n",
    "    # ),\n",
    "    #c(\"Product-destination fixed effect\",\n",
    "    #  \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"No\"#,\n",
    "      #\"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"No\"\n",
    "    # ),\n",
    "\n",
    "    #c(\"City-sector-year-regime\",\n",
    "    #  \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\"#, \"Yes\", \"Yes\"#,\n",
    "      #\"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"\n",
    "    # ),\n",
    "    \n",
    "    \n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3, t_4,t_5#,\n",
    "    #t_6, t_7, t_8, t_9, t_10, t_11\n",
    "),\n",
    "    title=\"VAT export rebate and product's quality upgrading, baseline regression\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"This table estimates eq(XX).\" \\\n",
    "\" Ln VAT rebate is the share entitled to reimboursement at the HS6 product.\" \\\n",
    "\" Note that 'Eligible' refers to the regime entitle to VAT refund, our treatment group.\" \\\n",
    "\" Our control group is processing trade with supplied input, 'Non-Eligible' to VAT refund.\" \\\n",
    "\" Sectors are defined following the Chinese 4-digit GB/T industry.\" \\\n",
    "\" classification and regroup several products.\" \\\n",
    "\" Heteroskedasticity-robust standard errors.\" \\\n",
    "\" clustered at the product level appear inparentheses.\"\\\n",
    "\" \\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\"\n",
    "\n",
    "#multicolumn ={\n",
    "#    'Quality': 4,\n",
    "    #'Price-adjusted': 5,\n",
    "#}\n",
    "multicolumn ={\n",
    "    '':1,\n",
    "    'Baseline':1,\n",
    "    'Shocks': 1,\n",
    "    'Balance': 1,\n",
    "    'Only 17\\%': 1,\n",
    "    'No zero rebate': 1\n",
    "}\n",
    "multi_lines_dep = '(city/product/trade regime/year)'\n",
    "new_r = [\n",
    "    #'& Eligible', 'Non-Eligible', \n",
    "    '& All','All benchmark', 'All', 'All benchmark',\n",
    "    #'Eligible', 'Non-Eligible', 'All','All benchmark', 'All', 'All benchmark',\n",
    "]\n",
    "\n",
    "reorder = {\n",
    "    2:0,\n",
    "    3:1\n",
    "}\n",
    "\n",
    "lb.beautify(table_number = table_nb,\n",
    "            reorder_var = reorder,\n",
    "            multi_lines_dep = multi_lines_dep,\n",
    "            #new_row= new_r,\n",
    "            multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 180,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 2: Heterogeneity effect\n",
    "\n",
    "- LDC and DC comes from the world bank classification, and are already in the table\n",
    "- The list of homogeneous goods is in the S3\n",
    "- Small/large city is be computed by using:\n",
    "    - the number of product exported in 2003. If the count of product is above average, then it can be consider as a large firm \n",
    "    - The average quantity\n",
    " \n",
    " \n",
    "* Column 1: Estimate baseline regression subset LDC countries: `income_group_ldc_dc` -> `LDC`\n",
    "* Column 2: Estimate baseline regression subset DC countries: `income_group_ldc_dc` -> `DC`\n",
    "* Column 3: Estimate baseline regression subset Homogeneous goods: `classification` -> `HOMOGENEOUS`\n",
    "* Column 4: Estimate baseline regression subset heterogeneous goods: `classification` -> != `HOMOGENEOUS`\n",
    "* Column 5: Estimate baseline regression subset small cities: `size_product` -> == `SMALL_COUNT`\n",
    "* Column 6: Estimate baseline regression subset large cities: `size_product` -> == `LARGE_COUNT`\n",
    "* Column 7: Estimate baseline regression subset small cities: `size_quantity` -> == `SMALL_QUANTITY`\n",
    "* Column 8: Estimate baseline regression subset large cities: `size_quantity` -> == `LARGE_QUANTITY`\n",
    "\n",
    "Sector is defined as the GBT 4 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 2\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "#for ext in ['.txt', '.tex', '.pdf']:\n",
    "#    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "#    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "#### COUNTRIES\n",
    "t_0 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(income_group_ldc_dc == 'LDC'),\n",
    "            exactDOF = TRUE)\n",
    "t_0 <- change_target(t_0)\n",
    "print('table 0 done')\n",
    "\n",
    "t_1 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(income_group_ldc_dc != 'LDC'),\n",
    "            exactDOF = TRUE)\n",
    "t_1 <- change_target(t_1)\n",
    "print('table 1 done')\n",
    "#### GOODS\n",
    "t_2 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax +\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(is.na(homogeneous) | homogeneous == 'HOMOGENEOUS'),\n",
    "            exactDOF = TRUE)\n",
    "t_2 <- change_target(t_2)\n",
    "print('table 2 done')\n",
    "\n",
    "t_3 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax +\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(homogeneous == 'HETEREGENEOUS'),\n",
    "            exactDOF = TRUE)\n",
    "t_3 <- change_target(t_3)\n",
    "print('table 3 done')\n",
    "#### CITIES\n",
    "##### HS6\n",
    "t_4 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(size_product == 'SMALL_COUNT'),\n",
    "            exactDOF = TRUE)\n",
    "t_4 <- change_target(t_4)\n",
    "print('table 4 done')\n",
    "\n",
    "t_5 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(size_product == 'LARGE_COUNT'),\n",
    "            exactDOF = TRUE)\n",
    "t_5 <- change_target(t_5)\n",
    "print('table 5 done')\n",
    "\n",
    "##### Quantity\n",
    "#t_6 <- felm(kandhelwal_quality ~ln_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax\n",
    "#            | fe_ckr + fe_csrt+fe_kt|0 | hs6, df_final %>% filter(size_quantity == 'SMALL_QUANTITY'),\n",
    "#            exactDOF = TRUE)\n",
    "#t_6 <- change_target(t_6)\n",
    "#print('table 6 done')\n",
    "\n",
    "#t_7 <- felm(kandhelwal_quality ~ln_rebate* regime + ln_lag_import_tax * regime+ ln_lag_import_tax\n",
    "#            | fe_ckr + fe_csrt+fe_kt|0 | hs6, df_final %>% filter(size_quantity == 'LARGE_QUANTITY'),\n",
    "#            exactDOF = TRUE)\n",
    "#t_7 <- change_target(t_7)\n",
    "#print('table 7 done')\n",
    "\n",
    "dep <- \"Dependent variable: Product quality\"\n",
    "fe1 <- list(\n",
    "    c(\"City-product-regime\",\"Yes\", \"Yes\", \"Yes\", \"Yes\",\"Yes\", \"Yes\"),\n",
    "    \n",
    "    c(\"Product-year\",\"Yes\", \"Yes\", \"Yes\", \"Yes\",\"Yes\", \"Yes\"),\n",
    "    \n",
    "    c(\"Destination-year\", \"Yes\", \"Yes\", \"Yes\", \"Yes\",\"Yes\", \"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3, t_4, t_5\n",
    "),\n",
    "    title=\"VAT export tax and firmâ€™s quality upgrading, characteristics of the destination countries, products, and cities\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"\"\"\n",
    "This table estimates eq(3). \n",
    "LDC and DC are defined according to the World Bank country classification.\n",
    "Homogeneous and heterogeneous goods are defined according to the official list of goods`s classification, Rauch (1999).\n",
    "Small and large are computed based on either the count of HS6 exported by city $c$ or the total quantity exported.\n",
    "When one of these two metrics are above national average, the city is considered as large.\n",
    "Note that 'Eligible' refers to the regime entitle to VAT refund, our treatment group.\n",
    "Our control group is processing trade with supplied input, 'Non-Eligible' to VAT refund.\n",
    "Sectors are defined following the Chinese 4-digit GB/T industry\n",
    "classification and regroup several products.\n",
    "Heteroskedasticity-robust standard errors\n",
    "clustered at the product level appear inparentheses.\n",
    "\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\"\"\"\n",
    "\n",
    "multicolumn ={\n",
    "    'LDC': 1,\n",
    "    'DC': 1,\n",
    "    'Homogeneous': 1,\n",
    "    'Heterogeneous': 1,\n",
    "    'Small HS6': 1,\n",
    "    'Large HS6': 1\n",
    "}\n",
    "multi_lines_dep = '(city/product/trade regime/year)'\n",
    "reorder = {\n",
    "    2:0,\n",
    "    3:1\n",
    "}\n",
    "#new_r = ['& Eligible', 'Non-Eligible', 'All', 'All benchmark']\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #multi_lines_dep = None,\n",
    "            reorder_var = reorder,\n",
    "            multi_lines_dep = multi_lines_dep,\n",
    "            new_row= False,\n",
    "            multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 180,\n",
    "           folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Table 3: Industry characteristicts\n",
    "\n",
    "* Column 1 excludes rare earth products with the main fixed effect:\n",
    "* Column 2 excludes energy intensive industries with the main fixed effect:\n",
    "* Column 3 excludes high tech industries with the main fixed effect:\n",
    "* Column 4 excludes RD oriented indusrtries with the main fixed effect:\n",
    "* Column 5 excludes High skilled oriented with the main fixed effect:\n",
    "  \n",
    "Sector is defined as the GBT 4 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "db = 'environment'\n",
    "query = \"\"\"\n",
    "WITH temp AS (\n",
    "SELECT ind2, SUM(tso2) as sum_tso2\n",
    "FROM environment.china_city_sector_pollution  \n",
    "WHERE year = '2002'\n",
    "GROUP BY ind2\n",
    "ORDER BY sum_tso2\n",
    "  )\n",
    "  SELECT *\n",
    "  FROM temp\n",
    "  LEFT JOIN (\n",
    "    SELECT cic as ind2, short\n",
    "    FROM chinese_lookup.ind_cic_2_name\n",
    "    ) as ind_name\n",
    "    ON temp.ind2 = ind_name.ind2\n",
    "\"\"\"\n",
    "list_polluted = s3.run_query(\n",
    "            query=query,\n",
    "            database=db,\n",
    "            s3_output='SQL_OUTPUT_ATHENA',\n",
    "            filename='polluted',  # Add filename to print dataframe\n",
    "            destination_key='SQL_OUTPUT_ATHENA/CSV',  #Use it temporarily\n",
    "        )\n",
    "list_polluted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    list_polluted.loc[lambda x: x['sum_tso2'] >=np.quantile(list_polluted['sum_tso2'], 0.75)]\n",
    "    .reindex(columns = ['ind2', 'short'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "folder = 'Tables_0'\n",
    "table_nb = 3\n",
    "table = 'table_{}'.format(table_nb)\n",
    "path = os.path.join(folder, table + '.txt')\n",
    "if os.path.exists(folder) == False:\n",
    "        os.mkdir(folder)\n",
    "#for ext in ['.txt', '.tex', '.pdf']:\n",
    "#    x = [a for a in os.listdir(folder) if a.endswith(ext)]\n",
    "#    [os.remove(os.path.join(folder, i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "to_remove <- c(\n",
    "  \"13\",\n",
    "\"17\",\n",
    "\"22\",\n",
    "\"25\",\n",
    "\"33\",\n",
    "\"26\",\n",
    "\"32\",\n",
    "\"31\"\n",
    ")\n",
    "#### RARE HEARTH\n",
    "t_0 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(hs6 != 850511),\n",
    "            exactDOF = TRUE)\n",
    "t_0 <- change_target(t_0)\n",
    "print('table 0 done')\n",
    "\n",
    "#### NO LARGE POLLUTED INDUSTRY\n",
    "t_1 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax +\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(!(hs2 %in% to_remove)),\n",
    "            exactDOF = TRUE)\n",
    "t_1 <- change_target(t_1)\n",
    "print('table 1 done')\n",
    "\n",
    "#### HIGH TECH\n",
    "t_2 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(is.na(high_tech)),\n",
    "            exactDOF = TRUE)\n",
    "t_2 <- change_target(t_2)\n",
    "print('table 2 done')\n",
    "#### SKILLED\n",
    "t_3 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(is.na(skilled)),\n",
    "            exactDOF = TRUE)\n",
    "t_3 <- change_target(t_3)\n",
    "print('table 3 done')\n",
    "##### RD\n",
    "t_4 <- felm(kandhelwal_quality ~ln_rebate_1* regime + ln_lag_import_tax * regime+ ln_lag_import_tax+\n",
    "            lag_foreign_export_share_ckr + lag_soe_export_share_ckr\n",
    "            | fe_ckr  + fe_kt + fe_jtr|0 | hs6, df_final %>% filter(is.na(rd_oriented)),\n",
    "            exactDOF = TRUE)\n",
    "t_4 <- change_target(t_4)\n",
    "print('table 4 done')\n",
    "\n",
    "dep <- \"Dependent variable: Product quality\"\n",
    "fe1 <- list(\n",
    "    c(\"City-product-regime\",\"Yes\", \"Yes\", \"Yes\", \"Yes\",\"Yes\"),\n",
    "    \n",
    "    c(\"Product-year\",\"Yes\", \"Yes\", \"Yes\", \"Yes\",\"Yes\"),\n",
    "    \n",
    "    c(\"Destination-year\", \"Yes\", \"Yes\", \"Yes\", \"Yes\",\"Yes\")\n",
    "             )\n",
    "\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3, t_4\n",
    "),\n",
    "    title=\"VAT export tax and firmâ€™s quality upgrading, characteristics of sensible sectors\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [],
   "source": [
    "%get path table\n",
    "table_1 <- go_latex(list(\n",
    "    t_0,t_1, t_2, t_3, t_4\n",
    "),\n",
    "    title=\"VAT export tax and firmâ€™s quality upgrading, characteristics of sensible sectors\",\n",
    "    dep_var = dep,\n",
    "    addFE=fe1,\n",
    "    save=TRUE,\n",
    "    note = FALSE,\n",
    "    name=path\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "tbe1  = \"\"\"\n",
    "This table estimates eq(3). \n",
    "Note that 'Eligible' refers to the regime entitle to VAT refund, our treatment group.\n",
    "Our control group is processing trade with supplied input, 'Non-Eligible' to VAT refund.\n",
    "Sectors are defined following the Chinese 4-digit GB/T industry\n",
    "classification and regroup several products.\n",
    "Heteroskedasticity-robust standard errors\n",
    "clustered at the product level appear inparentheses.\n",
    "\\sym{*} Significance at the 10\\%, \\sym{**} Significance at the 5\\%, \\sym{***} Significance at the 1\\%.\"\"\"\n",
    "\n",
    "multicolumn ={\n",
    "    'No rare-earth': 1,\n",
    "    'No polluted intensive': 1,\n",
    "    'No high tech': 1,\n",
    "    'No RD oriented': 1,\n",
    "    'No high skilled oriented': 1,\n",
    "}\n",
    "reorder = {\n",
    "    2:0,\n",
    "    3:1\n",
    "}\n",
    "multi_lines_dep = '(city/product/trade regime/year)'\n",
    "#new_r = ['& Eligible', 'Non-Eligible', 'All', 'All benchmark']\n",
    "lb.beautify(table_number = table_nb,\n",
    "            #multi_lines_dep = None,\n",
    "            reorder_var = reorder,\n",
    "            multi_lines_dep = multi_lines_dep,\n",
    "            new_row= False,\n",
    "            multicolumn = multicolumn,\n",
    "            table_nte = tbe1,\n",
    "            jupyter_preview = True,\n",
    "            resolution = 180,\n",
    "            folder = folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import os, time, shutil, urllib, ipykernel, json\n",
    "from pathlib import Path\n",
    "from notebook import notebookapp\n",
    "import sys\n",
    "path = os.getcwd()\n",
    "parent_path = str(Path(path).parent.parent.parent)\n",
    "sys.path.append(os.path.join(parent_path, 'utils'))\n",
    "import make_toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "name_json = 'parameters_ETL_VAT_rebate_quality_china.json'\n",
    "path_json = os.path.join(str(Path(path).parent.parent), 'utils',name_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "def create_report(extension = \"html\", keep_code = False, notebookname = None):\n",
    "    \"\"\"\n",
    "    Create a report from the current notebook and save it in the \n",
    "    Report folder (Parent-> child directory)\n",
    "    \n",
    "    1. Exctract the current notbook name\n",
    "    2. Convert the Notebook \n",
    "    3. Move the newly created report\n",
    "    \n",
    "    Args:\n",
    "    extension: string. Can be \"html\", \"pdf\", \"md\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get notebook name\n",
    "    connection_file = os.path.basename(ipykernel.get_connection_file())\n",
    "    kernel_id = connection_file.split('-', 1)[0].split('.')[0]\n",
    "\n",
    "    for srv in notebookapp.list_running_servers():\n",
    "        try:\n",
    "            if srv['token']=='' and not srv['password']:  \n",
    "                req = urllib.request.urlopen(srv['url']+'api/sessions')\n",
    "            else:\n",
    "                req = urllib.request.urlopen(srv['url']+ \\\n",
    "                                             'api/sessions?token=' + \\\n",
    "                                             srv['token'])\n",
    "            sessions = json.load(req)\n",
    "            notebookname = sessions[0]['name']\n",
    "        except:\n",
    "            notebookname = notebookname  \n",
    "    \n",
    "    sep = '.'\n",
    "    path = os.getcwd()\n",
    "    #parent_path = str(Path(path).parent)\n",
    "    \n",
    "    ### Path report\n",
    "    #path_report = \"{}/Reports\".format(parent_path)\n",
    "    #path_report = \"{}/Reports\".format(path)\n",
    "    \n",
    "    ### Path destination\n",
    "    name_no_extension = notebookname.split(sep, 1)[0]\n",
    "    source_to_move = name_no_extension +'.{}'.format(extension)\n",
    "    dest = os.path.join(path,'Reports', source_to_move)\n",
    "    \n",
    "    ### Generate notebook\n",
    "    if keep_code:\n",
    "        os.system('jupyter nbconvert --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    else:\n",
    "        os.system('jupyter nbconvert --no-input --to {} {}'.format(\n",
    "    extension,notebookname))\n",
    "    \n",
    "    ### Move notebook to report folder\n",
    "    #time.sleep(5)\n",
    "    shutil.move(source_to_move, dest)\n",
    "    print(\"Report Available at this adress:\\n {}\".format(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3",
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "create_report(extension = \"html\", keep_code = True, notebookname = \"00_baseline_vat_quality.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "python3"
   },
   "outputs": [],
   "source": [
    "### Update TOC in Github\n",
    "for p in [parent_path,\n",
    "          str(Path(path).parent),\n",
    "          #os.path.join(str(Path(path).parent), \"00_download_data_from\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\", \"00_statistical_exploration\"),\n",
    "          #os.path.join(str(Path(path).parent.parent), \"02_data_analysis\", \"01_model_estimation\"),\n",
    "         ]:\n",
    "    try:\n",
    "        os.remove(os.path.join(p, 'README.md'))\n",
    "    except:\n",
    "        pass\n",
    "    path_parameter = os.path.join(parent_path,'utils', name_json)\n",
    "    md_lines =  make_toc.create_index(cwd = p, path_parameter = path_parameter)\n",
    "    md_out_fn = os.path.join(p,'README.md')\n",
    "    \n",
    "    if p == parent_path:\n",
    "    \n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = True, path_parameter = path_parameter)\n",
    "    else:\n",
    "        make_toc.replace_index(md_out_fn, md_lines, Header = os.path.basename(p).replace('_', ' '), add_description = False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "nteract": {
   "version": "0.26.0"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ],
    [
     "python3",
     "python3",
     "python",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ]
   ],
   "version": "0.20.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
